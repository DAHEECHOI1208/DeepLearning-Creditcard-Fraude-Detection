{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import numpy\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import SGD\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_dim=29, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\toptimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\treturn model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=0)\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(X, Y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "\t# create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=29, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    optimizer = SGD(lr=learn_rate, momentum=momentum)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full = pd.read_csv(\"/home/dinesh/Downloads/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full.sort_values(by='Class', ascending=False, inplace=True) \n",
    "df_full.drop('Time', axis=1,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster = df_full.iloc[493:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(df_cluster.drop(\"Class\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "labels = pd.Series(kmeans.labels_)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinesh/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_cluster['clust']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    203273\n",
       "0.0     50401\n",
       "7.0     18190\n",
       "6.0      7153\n",
       "2.0      3044\n",
       "8.0      1182\n",
       "1.0       380\n",
       "5.0       167\n",
       "9.0        28\n",
       "4.0         3\n",
       "Name: clust, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.clust.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_0=df_cluster.loc[df_cluster['clust'] == 0.0]\n",
    "df_cluster_1=df_cluster.loc[df_cluster['clust'] == 1.0]\n",
    "df_cluster_2=df_cluster.loc[df_cluster['clust'] == 2.0]\n",
    "df_cluster_3=df_cluster.loc[df_cluster['clust'] == 3.0]\n",
    "df_cluster_4=df_cluster.loc[df_cluster['clust'] == 4.0]\n",
    "df_cluster_5=df_cluster.loc[df_cluster['clust'] == 5.0]\n",
    "df_cluster_6=df_cluster.loc[df_cluster['clust'] == 6.0]\n",
    "df_cluster_7=df_cluster.loc[df_cluster['clust'] == 7.0]\n",
    "df_cluster_8=df_cluster.loc[df_cluster['clust'] == 8.0]\n",
    "df_cluster_9=df_cluster.loc[df_cluster['clust'] == 9.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_cluster=pd.concat([df_cluster_3.sample(frac=0.01),df_cluster_0.sample(frac=0.01),df_cluster_7.sample(frac=0.01),df_cluster_6.sample(frac=0.01),df_cluster_2.sample(frac=0.1),df_cluster_8.sample(frac=0.1),df_cluster_1,df_cluster_5,df_cluster_9,df_cluster_4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0    2033\n",
       "0.0     504\n",
       "1.0     380\n",
       "2.0     304\n",
       "7.0     182\n",
       "5.0     167\n",
       "8.0     118\n",
       "6.0      72\n",
       "9.0      28\n",
       "4.0       3\n",
       "Name: clust, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_cluster.clust.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_cluster=df_sample_cluster.drop('clust',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample=pd.concat([df_full.iloc[:492,:],df_sample_cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = np.array(df_sample.values[:,0:29])\n",
    "label = np.array(df_sample.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_sample, test_size=0.2, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature = np.array(df_train.values[:,0:29])\n",
    "train_label = np.array(df_train.values[:,-1])\n",
    "test_feature = np.array(df_test.values[:,0:29])\n",
    "test_label = np.array(df_test.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(train_feature)\n",
    "train_feature_trans = scaler.transform(train_feature)\n",
    "test_feature_trans = scaler.transform(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=20, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# define the grid search parameters\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "param_grid = dict(learn_rate=learn_rate, momentum=momentum)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1)\n",
    "grid_result = grid.fit(train_feature_trans, train_label )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.980152 using {'learn_rate': 0.01, 'momentum': 0.9}\n",
      "0.885873 (0.005414) with: {'learn_rate': 0.001, 'momentum': 0.0}\n",
      "0.902510 (0.014763) with: {'learn_rate': 0.001, 'momentum': 0.2}\n",
      "0.915645 (0.007162) with: {'learn_rate': 0.001, 'momentum': 0.4}\n",
      "0.932283 (0.005461) with: {'learn_rate': 0.001, 'momentum': 0.6}\n",
      "0.968768 (0.000413) with: {'learn_rate': 0.001, 'momentum': 0.8}\n",
      "0.976065 (0.002977) with: {'learn_rate': 0.001, 'momentum': 0.9}\n",
      "0.975773 (0.002707) with: {'learn_rate': 0.01, 'momentum': 0.0}\n",
      "0.977233 (0.003783) with: {'learn_rate': 0.01, 'momentum': 0.2}\n",
      "0.978109 (0.002477) with: {'learn_rate': 0.01, 'momentum': 0.4}\n",
      "0.979568 (0.003224) with: {'learn_rate': 0.01, 'momentum': 0.6}\n",
      "0.979860 (0.003575) with: {'learn_rate': 0.01, 'momentum': 0.8}\n",
      "0.980152 (0.003302) with: {'learn_rate': 0.01, 'momentum': 0.9}\n",
      "0.978984 (0.004465) with: {'learn_rate': 0.1, 'momentum': 0.0}\n",
      "0.979860 (0.004953) with: {'learn_rate': 0.1, 'momentum': 0.2}\n",
      "0.976649 (0.004761) with: {'learn_rate': 0.1, 'momentum': 0.4}\n",
      "0.977525 (0.004189) with: {'learn_rate': 0.1, 'momentum': 0.6}\n",
      "0.978984 (0.004290) with: {'learn_rate': 0.1, 'momentum': 0.8}\n",
      "0.980152 (0.003302) with: {'learn_rate': 0.1, 'momentum': 0.9}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.2, 'momentum': 0.0}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.2, 'momentum': 0.2}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.2, 'momentum': 0.4}\n",
      "0.978400 (0.002511) with: {'learn_rate': 0.2, 'momentum': 0.6}\n",
      "0.973147 (0.009601) with: {'learn_rate': 0.2, 'momentum': 0.8}\n",
      "0.979860 (0.002578) with: {'learn_rate': 0.2, 'momentum': 0.9}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.3, 'momentum': 0.0}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.3, 'momentum': 0.2}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.3, 'momentum': 0.4}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.3, 'momentum': 0.6}\n",
      "0.944542 (0.046918) with: {'learn_rate': 0.3, 'momentum': 0.8}\n",
      "0.885289 (0.004953) with: {'learn_rate': 0.3, 'momentum': 0.9}\n"
     ]
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
