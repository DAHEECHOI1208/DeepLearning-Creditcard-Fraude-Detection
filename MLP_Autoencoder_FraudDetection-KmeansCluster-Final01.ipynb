{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #Credit Card Fraud Detection using DeepLearning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score,fbeta_score,classification_report,confusion_matrix,precision_recall_curve,roc_auc_score\\\n",
    "    ,roc_curve\n",
    "from subprocess import check_output\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "import tflearn\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.normalization import batch_normalization, local_response_normalization\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import skew\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/home/dinesh/Downloads/creditcard.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_fraud=data[data[\"Class\"]==1]\n",
    "data_non_fraud=data[data[\"Class\"]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((492, 31), (284315, 31))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fraud.shape, data_non_fraud.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "data_fraud_train, data_fraud_test=train_test_split(data_fraud,test_size=0.2, shuffle=False)\n",
    "data_non_fraud_train, data_non_fraud_test=train_test_split(data_non_fraud,test_size=0.2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((393, 31), (99, 31), (227452, 31), (56863, 31))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fraud_train.shape, data_fraud_test.shape, data_non_fraud_train.shape, data_non_fraud_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train=pd.concat([data_fraud_train,data_non_fraud_train])\n",
    "data_test=pd.concat([data_fraud_test,data_non_fraud_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227845, 31)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full=data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>-0.270953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4920</th>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>-0.238253</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>-0.247768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>-1.282858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Time        V1        V2        V3        V4        V5        V6  \\\n",
       "541    406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545   \n",
       "623    472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805 -1.064823   \n",
       "4920  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628 -0.075788   \n",
       "6108  6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131 -1.706536   \n",
       "6329  7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201 -1.357746   \n",
       "\n",
       "            V7        V8        V9  ...         V21       V22       V23  \\\n",
       "541  -2.537387  1.391657 -2.770089  ...    0.517232 -0.035049 -0.465211   \n",
       "623   0.325574 -0.067794 -0.270953  ...    0.661696  0.435477  1.375966   \n",
       "4920  0.562320 -0.399147 -0.238253  ...   -0.294166 -0.932391  0.172726   \n",
       "6108 -3.496197 -0.248778 -0.247768  ...    0.573574  0.176968 -0.436207   \n",
       "6329  1.713445 -0.496358 -1.282858  ...   -0.379068 -0.704181 -0.656805   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "541   0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "623  -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "4920 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "6108 -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "6329 -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_full = pd.read_csv(\"/home/dinesh/Downloads/creditcard.csv\")\n",
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    227452\n",
       "1       393\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.Class.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_full.sort_values(by='Class', ascending=False, inplace=True) \n",
    "df_full.drop('Time', axis=1,  inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>-2.770089</td>\n",
       "      <td>-2.772272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142557</th>\n",
       "      <td>-1.430864</td>\n",
       "      <td>-0.802529</td>\n",
       "      <td>1.123320</td>\n",
       "      <td>0.389760</td>\n",
       "      <td>-0.281214</td>\n",
       "      <td>-0.055123</td>\n",
       "      <td>1.326232</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>-0.546890</td>\n",
       "      <td>-0.713474</td>\n",
       "      <td>...</td>\n",
       "      <td>0.325575</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.114963</td>\n",
       "      <td>0.156365</td>\n",
       "      <td>-0.619437</td>\n",
       "      <td>-0.120351</td>\n",
       "      <td>0.035594</td>\n",
       "      <td>354.33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141260</th>\n",
       "      <td>-1.927453</td>\n",
       "      <td>1.827621</td>\n",
       "      <td>-7.019495</td>\n",
       "      <td>5.348303</td>\n",
       "      <td>-2.739188</td>\n",
       "      <td>-2.107219</td>\n",
       "      <td>-5.015848</td>\n",
       "      <td>1.205868</td>\n",
       "      <td>-4.382713</td>\n",
       "      <td>-8.337707</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376938</td>\n",
       "      <td>-0.792017</td>\n",
       "      <td>-0.771414</td>\n",
       "      <td>-0.379574</td>\n",
       "      <td>0.718717</td>\n",
       "      <td>1.111151</td>\n",
       "      <td>1.277707</td>\n",
       "      <td>0.819081</td>\n",
       "      <td>512.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141259</th>\n",
       "      <td>-1.927453</td>\n",
       "      <td>1.827621</td>\n",
       "      <td>-7.019495</td>\n",
       "      <td>5.348303</td>\n",
       "      <td>-2.739188</td>\n",
       "      <td>-2.107219</td>\n",
       "      <td>-5.015848</td>\n",
       "      <td>1.205868</td>\n",
       "      <td>-4.382713</td>\n",
       "      <td>-8.337707</td>\n",
       "      <td>...</td>\n",
       "      <td>1.376938</td>\n",
       "      <td>-0.792017</td>\n",
       "      <td>-0.771414</td>\n",
       "      <td>-0.379574</td>\n",
       "      <td>0.718717</td>\n",
       "      <td>1.111151</td>\n",
       "      <td>1.277707</td>\n",
       "      <td>0.819081</td>\n",
       "      <td>512.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141258</th>\n",
       "      <td>-0.937843</td>\n",
       "      <td>3.462889</td>\n",
       "      <td>-6.445104</td>\n",
       "      <td>4.932199</td>\n",
       "      <td>-2.233983</td>\n",
       "      <td>-2.291561</td>\n",
       "      <td>-5.695594</td>\n",
       "      <td>1.338825</td>\n",
       "      <td>-4.322377</td>\n",
       "      <td>-8.099119</td>\n",
       "      <td>...</td>\n",
       "      <td>1.066550</td>\n",
       "      <td>-0.521657</td>\n",
       "      <td>-0.319917</td>\n",
       "      <td>-0.405859</td>\n",
       "      <td>0.906802</td>\n",
       "      <td>1.165784</td>\n",
       "      <td>1.374495</td>\n",
       "      <td>0.729889</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "541    -2.312227  1.951992 -1.609851  3.997906 -0.522188 -1.426545 -2.537387   \n",
       "142557 -1.430864 -0.802529  1.123320  0.389760 -0.281214 -0.055123  1.326232   \n",
       "141260 -1.927453  1.827621 -7.019495  5.348303 -2.739188 -2.107219 -5.015848   \n",
       "141259 -1.927453  1.827621 -7.019495  5.348303 -2.739188 -2.107219 -5.015848   \n",
       "141258 -0.937843  3.462889 -6.445104  4.932199 -2.233983 -2.291561 -5.695594   \n",
       "\n",
       "              V8        V9       V10  ...         V21       V22       V23  \\\n",
       "541     1.391657 -2.770089 -2.772272  ...    0.517232 -0.035049 -0.465211   \n",
       "142557  0.195700 -0.546890 -0.713474  ...    0.325575  0.014002  0.844946   \n",
       "141260  1.205868 -4.382713 -8.337707  ...    1.376938 -0.792017 -0.771414   \n",
       "141259  1.205868 -4.382713 -8.337707  ...    1.376938 -0.792017 -0.771414   \n",
       "141258  1.338825 -4.322377 -8.099119  ...    1.066550 -0.521657 -0.319917   \n",
       "\n",
       "             V24       V25       V26       V27       V28  Amount  Class  \n",
       "541     0.320198  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "142557  0.114963  0.156365 -0.619437 -0.120351  0.035594  354.33      1  \n",
       "141260 -0.379574  0.718717  1.111151  1.277707  0.819081  512.25      1  \n",
       "141259 -0.379574  0.718717  1.111151  1.277707  0.819081  512.25      1  \n",
       "141258 -0.405859  0.906802  1.165784  1.374495  0.729889    0.00      1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster = df_full.iloc[393:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(227452, 30)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b9e4a5e29364>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mKM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cluster\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-b9e4a5e29364>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mKM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cluster\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mcentroids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mKM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    891\u001b[0m                 \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy_x\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgorithm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 return_n_iter=True)\n\u001b[0m\u001b[1;32m    894\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36mk_means\u001b[0;34m(X, n_clusters, init, precompute_distances, n_init, max_iter, verbose, tol, random_state, copy_x, n_jobs, algorithm, return_n_iter)\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m                 \u001b[0mprecompute_distances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprecompute_distances\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m                 x_squared_norms=x_squared_norms, random_state=random_state)\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;31m# determine if these results are the best so far\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbest_inertia\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minertia\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_inertia\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/sklearn/cluster/k_means_.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, precompute_distances)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Initialization complete'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     centers, labels, n_iter = k_means_elkan(X, n_clusters, centers, tol=tol,\n\u001b[0;32m--> 400\u001b[0;31m                                             max_iter=max_iter, verbose=verbose)\n\u001b[0m\u001b[1;32m    401\u001b[0m     \u001b[0minertia\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minertia\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/cluster/_k_means_elkan.pyx\u001b[0m in \u001b[0;36msklearn.cluster._k_means_elkan.k_means_elkan\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36msum\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NoValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1731\u001b[0m     \"\"\"\n\u001b[1;32m   1732\u001b[0m     \u001b[0mSum\u001b[0m \u001b[0mof\u001b[0m \u001b[0marray\u001b[0m \u001b[0melements\u001b[0m \u001b[0mover\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cdist, pdist\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "K = range(1,20)\n",
    "KM = [KMeans(n_clusters=k).fit(df_cluster) for k in K]\n",
    "centroids = [k.cluster_centers_ for k in KM]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_k = [cdist(df_cluster, cent, 'euclidean') for cent in centroids]\n",
    "cIdx = [np.argmin(D,axis=1) for D in D_k]\n",
    "dist = [np.min(D,axis=1) for D in D_k]\n",
    "avgWithinSS = [sum(d)/df_cluster.shape[0] for d in dist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdist(df_cluster,'euclidean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d90c864a8>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6d8eb94320>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,0,'Number of clusters')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Average within-cluster sum of squares')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Elbow for KMeans clustering')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6d91c449b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# elbow curve\n",
    "\n",
    "kIdx = 20-2\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(K, avgWithinSS, 'b*-')\n",
    "ax.plot(K[kIdx], avgWithinSS[kIdx], marker='o', markersize=12, markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average within-cluster sum of squares')\n",
    "plt.title('Elbow for KMeans clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans=KMeans(n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=10, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.fit(df_cluster.drop(\"Class\",axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k=10\n",
    "labels = pd.Series(kmeans.labels_)\n",
    "centroids = kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinesh/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_cluster['clust']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    159482\n",
       "9.0     41058\n",
       "8.0     15079\n",
       "0.0      6559\n",
       "4.0      2846\n",
       "6.0      1241\n",
       "2.0       495\n",
       "5.0       222\n",
       "3.0        48\n",
       "7.0         5\n",
       "Name: clust, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cluster.clust.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cluster_0=df_cluster.loc[df_cluster['clust'] == 0.0]\n",
    "df_cluster_1=df_cluster.loc[df_cluster['clust'] == 1.0]\n",
    "df_cluster_2=df_cluster.loc[df_cluster['clust'] == 2.0]\n",
    "df_cluster_3=df_cluster.loc[df_cluster['clust'] == 3.0]\n",
    "df_cluster_4=df_cluster.loc[df_cluster['clust'] == 4.0]\n",
    "df_cluster_5=df_cluster.loc[df_cluster['clust'] == 5.0]\n",
    "df_cluster_6=df_cluster.loc[df_cluster['clust'] == 6.0]\n",
    "df_cluster_7=df_cluster.loc[df_cluster['clust'] == 7.0]\n",
    "df_cluster_8=df_cluster.loc[df_cluster['clust'] == 8.0]\n",
    "df_cluster_9=df_cluster.loc[df_cluster['clust'] == 9.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#df_sample_cluster=pd.concat([df_cluster_3.sample(frac=0.01),df_cluster_0.sample(frac=0.01),df_cluster_7.sample(frac=0.01),df_cluster_6.sample(frac=0.01),df_cluster_2.sample(frac=0.1),df_cluster_8.sample(frac=0.1),df_cluster_1,df_cluster_5,df_cluster_9,df_cluster_4])\n",
    "\n",
    "df_sample_cluster=pd.concat([df_cluster_1.sample(frac=0.01),df_cluster_9.sample(frac=0.01),df_cluster_8.sample(frac=0.01),df_cluster_0.sample(frac=0.01),df_cluster_4.sample(frac=0.1),df_cluster_6.sample(frac=0.1),df_cluster_2,df_cluster_3,df_cluster_7,df_cluster_5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3402, 31)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    1595\n",
       "2.0     495\n",
       "9.0     411\n",
       "4.0     285\n",
       "5.0     222\n",
       "8.0     151\n",
       "6.0     124\n",
       "0.0      66\n",
       "3.0      48\n",
       "7.0       5\n",
       "Name: clust, dtype: int64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_cluster.clust.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "      <th>clust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>199934</th>\n",
       "      <td>-0.257022</td>\n",
       "      <td>0.926352</td>\n",
       "      <td>-0.696905</td>\n",
       "      <td>-1.012072</td>\n",
       "      <td>0.803521</td>\n",
       "      <td>0.161527</td>\n",
       "      <td>0.400225</td>\n",
       "      <td>0.605277</td>\n",
       "      <td>-0.213930</td>\n",
       "      <td>-0.437131</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.832947</td>\n",
       "      <td>0.043502</td>\n",
       "      <td>-0.396128</td>\n",
       "      <td>-0.374679</td>\n",
       "      <td>0.160215</td>\n",
       "      <td>0.101116</td>\n",
       "      <td>0.018917</td>\n",
       "      <td>8.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192552</th>\n",
       "      <td>2.236114</td>\n",
       "      <td>-0.511869</td>\n",
       "      <td>-2.080279</td>\n",
       "      <td>-0.895475</td>\n",
       "      <td>-0.041324</td>\n",
       "      <td>-1.711956</td>\n",
       "      <td>0.304936</td>\n",
       "      <td>-0.625108</td>\n",
       "      <td>-0.999185</td>\n",
       "      <td>0.911978</td>\n",
       "      <td>...</td>\n",
       "      <td>1.036502</td>\n",
       "      <td>-0.087879</td>\n",
       "      <td>-0.013321</td>\n",
       "      <td>0.442594</td>\n",
       "      <td>0.084730</td>\n",
       "      <td>-0.078165</td>\n",
       "      <td>-0.078742</td>\n",
       "      <td>31.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98993</th>\n",
       "      <td>-0.801219</td>\n",
       "      <td>1.249365</td>\n",
       "      <td>1.179805</td>\n",
       "      <td>1.261428</td>\n",
       "      <td>-0.220622</td>\n",
       "      <td>0.228266</td>\n",
       "      <td>0.168084</td>\n",
       "      <td>0.680274</td>\n",
       "      <td>-0.703073</td>\n",
       "      <td>-0.156973</td>\n",
       "      <td>...</td>\n",
       "      <td>0.390015</td>\n",
       "      <td>-0.073866</td>\n",
       "      <td>0.240609</td>\n",
       "      <td>-0.130435</td>\n",
       "      <td>-0.250507</td>\n",
       "      <td>0.298158</td>\n",
       "      <td>0.133746</td>\n",
       "      <td>13.85</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223180</th>\n",
       "      <td>-0.022620</td>\n",
       "      <td>0.785036</td>\n",
       "      <td>-1.137932</td>\n",
       "      <td>-0.555141</td>\n",
       "      <td>0.209390</td>\n",
       "      <td>-0.095176</td>\n",
       "      <td>0.386935</td>\n",
       "      <td>0.541045</td>\n",
       "      <td>0.091331</td>\n",
       "      <td>-0.975526</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.508874</td>\n",
       "      <td>0.575099</td>\n",
       "      <td>-0.023337</td>\n",
       "      <td>-1.332301</td>\n",
       "      <td>-0.277858</td>\n",
       "      <td>-0.202588</td>\n",
       "      <td>-0.051718</td>\n",
       "      <td>81.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68072</th>\n",
       "      <td>1.002656</td>\n",
       "      <td>-1.570845</td>\n",
       "      <td>0.784708</td>\n",
       "      <td>-0.605882</td>\n",
       "      <td>-1.779542</td>\n",
       "      <td>-0.077622</td>\n",
       "      <td>-1.183360</td>\n",
       "      <td>0.130541</td>\n",
       "      <td>0.114864</td>\n",
       "      <td>0.538741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.835663</td>\n",
       "      <td>-0.332157</td>\n",
       "      <td>-0.321564</td>\n",
       "      <td>0.276943</td>\n",
       "      <td>-0.014186</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.058184</td>\n",
       "      <td>218.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              V1        V2        V3        V4        V5        V6        V7  \\\n",
       "199934 -0.257022  0.926352 -0.696905 -1.012072  0.803521  0.161527  0.400225   \n",
       "192552  2.236114 -0.511869 -2.080279 -0.895475 -0.041324 -1.711956  0.304936   \n",
       "98993  -0.801219  1.249365  1.179805  1.261428 -0.220622  0.228266  0.168084   \n",
       "223180 -0.022620  0.785036 -1.137932 -0.555141  0.209390 -0.095176  0.386935   \n",
       "68072   1.002656 -1.570845  0.784708 -0.605882 -1.779542 -0.077622 -1.183360   \n",
       "\n",
       "              V8        V9       V10  ...         V22       V23       V24  \\\n",
       "199934  0.605277 -0.213930 -0.437131  ...   -0.832947  0.043502 -0.396128   \n",
       "192552 -0.625108 -0.999185  0.911978  ...    1.036502 -0.087879 -0.013321   \n",
       "98993   0.680274 -0.703073 -0.156973  ...    0.390015 -0.073866  0.240609   \n",
       "223180  0.541045  0.091331 -0.975526  ...   -1.508874  0.575099 -0.023337   \n",
       "68072   0.130541  0.114864  0.538741  ...    0.835663 -0.332157 -0.321564   \n",
       "\n",
       "             V25       V26       V27       V28  Amount  Class  clust  \n",
       "199934 -0.374679  0.160215  0.101116  0.018917    8.99      0    1.0  \n",
       "192552  0.442594  0.084730 -0.078165 -0.078742   31.00      0    1.0  \n",
       "98993  -0.130435 -0.250507  0.298158  0.133746   13.85      0    1.0  \n",
       "223180 -1.332301 -0.277858 -0.202588 -0.051718   81.00      0    1.0  \n",
       "68072   0.276943 -0.014186  0.006483  0.058184  218.00      0    1.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample_cluster=df_sample_cluster.drop('clust',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sample=pd.concat([df_full.iloc[:492,:],df_sample_cluster])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3501\n",
       "1     393\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = np.array(df_sample.values[:,0:29])\n",
    "label = np.array(df_sample.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df_sample, test_size=0.2, random_state=40)\n",
    "#df_train = shuffle_df[0:4000]\n",
    "#df_test = shuffle_df[4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_feature = np.array(df_train.values[:,0:29])\n",
    "train_label = np.array(df_train.values[:,-1])\n",
    "test_feature = np.array(df_test.values[:,0:29])\n",
    "test_label = np.array(df_test.values[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(train_feature)\n",
    "train_feature_trans = scaler.transform(train_feature)\n",
    "test_feature_trans = scaler.transform(test_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3115, 29), (779, 29))"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_feature_trans.shape,test_feature_trans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Building the encoder.\n",
    "encoder = tflearn.input_data(shape=[None, 29])\n",
    "encoder = tflearn.fully_connected(encoder, 128)\n",
    "encoder = tflearn.fully_connected(encoder, 64)\n",
    "\n",
    "# Building the decoder.\n",
    "decoder = tflearn.fully_connected(encoder, 128)\n",
    "decoder = tflearn.fully_connected(decoder, 29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Regression, with mean square error.\n",
    "net = tflearn.regression(decoder, optimizer='adam', learning_rate=0.001, loss='mean_square', metric=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 1299  | total loss: \u001b[1m\u001b[32m0.00537\u001b[0m\u001b[0m | time: 0.147s\n",
      "| Adam | epoch: 100 | loss: 0.00537 -- iter: 3072/3115\n",
      "Training Step: 1300  | total loss: \u001b[1m\u001b[32m0.00536\u001b[0m\u001b[0m | time: 1.163s\n",
      "| Adam | epoch: 100 | loss: 0.00536 | val_loss: 0.00509 -- iter: 3115/3115\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "# Training the auto encoder.\n",
    "model = tflearn.DNN(net, tensorboard_verbose=0)\n",
    "model.fit(train_feature_trans, train_feature_trans, n_epoch=100, validation_set=(test_feature_trans,test_feature_trans),run_id=\"auto_encoder\", batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#encode_decode = np.array(model.predict(testX))\n",
    "\n",
    "# New model, re-using the same session, for weights sharing.\n",
    "encoding_model = tflearn.DNN(encoder, session=model.session)\n",
    "#new_X = np.array(encoding_model.predict(X))\n",
    "#new_testX = np.array(encoding_model.predict(testX))\n",
    "new_X = np.array(model.predict(train_feature_trans))\n",
    "new_testX = np.array(model.predict(test_feature_trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "def show_train_history(train_history,train,validation):\n",
    "    plt.plot(train_history.history[train])\n",
    "    plt.plot(train_history.history[validation])\n",
    "    plt.title('Train History')\n",
    "    plt.ylabel(train)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'validation'], loc='best')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 200)               6000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 46,401\n",
      "Trainable params: 46,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "\n",
    "model.add(Dense(units=200, \n",
    "                input_dim=29, \n",
    "                kernel_initializer='glorot_normal', \n",
    "                activation='tanh'))\n",
    "model.add(Dropout(0.0))\n",
    "\n",
    "\n",
    "model.add(Dense(units=200,  \n",
    "                kernel_initializer='glorot_normal', \n",
    "                activation='tanh'))\n",
    "model.add(Dropout(0.0))\n",
    "\n",
    "\n",
    "model.add(Dense(units=1, \n",
    "                kernel_initializer='glorot_normal',\n",
    "                activation='sigmoid'))\n",
    "\n",
    "print(model.summary()) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 622 samples, validate on 2493 samples\n",
      "Epoch 1/200\n",
      "0s - loss: 0.7908 - acc: 0.2476 - val_loss: 0.3561 - val_acc: 0.9005\n",
      "Epoch 2/200\n",
      "0s - loss: 0.3643 - acc: 0.8907 - val_loss: 0.3039 - val_acc: 0.9005\n",
      "Epoch 3/200\n",
      "0s - loss: 0.3288 - acc: 0.8907 - val_loss: 0.3316 - val_acc: 0.9005\n",
      "Epoch 4/200\n",
      "0s - loss: 0.3625 - acc: 0.8907 - val_loss: 0.3465 - val_acc: 0.9005\n",
      "Epoch 5/200\n",
      "0s - loss: 0.3777 - acc: 0.8907 - val_loss: 0.3392 - val_acc: 0.9005\n",
      "Epoch 6/200\n",
      "0s - loss: 0.3672 - acc: 0.8907 - val_loss: 0.3168 - val_acc: 0.9005\n",
      "Epoch 7/200\n",
      "0s - loss: 0.3413 - acc: 0.8907 - val_loss: 0.2906 - val_acc: 0.9005\n",
      "Epoch 8/200\n",
      "0s - loss: 0.3114 - acc: 0.8907 - val_loss: 0.2728 - val_acc: 0.9005\n",
      "Epoch 9/200\n",
      "0s - loss: 0.2893 - acc: 0.8907 - val_loss: 0.2719 - val_acc: 0.9005\n",
      "Epoch 10/200\n",
      "0s - loss: 0.2867 - acc: 0.8907 - val_loss: 0.2832 - val_acc: 0.9005\n",
      "Epoch 11/200\n",
      "0s - loss: 0.2947 - acc: 0.8907 - val_loss: 0.2864 - val_acc: 0.9089\n",
      "Epoch 12/200\n",
      "0s - loss: 0.2957 - acc: 0.8987 - val_loss: 0.2717 - val_acc: 0.9150\n",
      "Epoch 13/200\n",
      "0s - loss: 0.2810 - acc: 0.9035 - val_loss: 0.2526 - val_acc: 0.9021\n",
      "Epoch 14/200\n",
      "0s - loss: 0.2638 - acc: 0.8907 - val_loss: 0.2424 - val_acc: 0.9005\n",
      "Epoch 15/200\n",
      "0s - loss: 0.2561 - acc: 0.8907 - val_loss: 0.2392 - val_acc: 0.9005\n",
      "Epoch 16/200\n",
      "0s - loss: 0.2547 - acc: 0.8907 - val_loss: 0.2369 - val_acc: 0.9005\n",
      "Epoch 17/200\n",
      "0s - loss: 0.2527 - acc: 0.8907 - val_loss: 0.2314 - val_acc: 0.9138\n",
      "Epoch 18/200\n",
      "0s - loss: 0.2463 - acc: 0.9035 - val_loss: 0.2223 - val_acc: 0.9226\n",
      "Epoch 19/200\n",
      "0s - loss: 0.2348 - acc: 0.9100 - val_loss: 0.2131 - val_acc: 0.9286\n",
      "Epoch 20/200\n",
      "0s - loss: 0.2240 - acc: 0.9148 - val_loss: 0.2099 - val_acc: 0.9290\n",
      "Epoch 21/200\n",
      "0s - loss: 0.2179 - acc: 0.9196 - val_loss: 0.2103 - val_acc: 0.9366\n",
      "Epoch 22/200\n",
      "0s - loss: 0.2172 - acc: 0.9293 - val_loss: 0.2053 - val_acc: 0.9370\n",
      "Epoch 23/200\n",
      "0s - loss: 0.2109 - acc: 0.9293 - val_loss: 0.1937 - val_acc: 0.9370\n",
      "Epoch 24/200\n",
      "0s - loss: 0.2000 - acc: 0.9293 - val_loss: 0.1854 - val_acc: 0.9366\n",
      "Epoch 25/200\n",
      "0s - loss: 0.1924 - acc: 0.9293 - val_loss: 0.1817 - val_acc: 0.9366\n",
      "Epoch 26/200\n",
      "0s - loss: 0.1898 - acc: 0.9293 - val_loss: 0.1778 - val_acc: 0.9370\n",
      "Epoch 27/200\n",
      "0s - loss: 0.1846 - acc: 0.9293 - val_loss: 0.1716 - val_acc: 0.9390\n",
      "Epoch 28/200\n",
      "0s - loss: 0.1768 - acc: 0.9325 - val_loss: 0.1673 - val_acc: 0.9438\n",
      "Epoch 29/200\n",
      "0s - loss: 0.1724 - acc: 0.9405 - val_loss: 0.1654 - val_acc: 0.9479\n",
      "Epoch 30/200\n",
      "0s - loss: 0.1691 - acc: 0.9486 - val_loss: 0.1603 - val_acc: 0.9479\n",
      "Epoch 31/200\n",
      "0s - loss: 0.1643 - acc: 0.9486 - val_loss: 0.1552 - val_acc: 0.9479\n",
      "Epoch 32/200\n",
      "0s - loss: 0.1589 - acc: 0.9486 - val_loss: 0.1516 - val_acc: 0.9479\n",
      "Epoch 33/200\n",
      "0s - loss: 0.1552 - acc: 0.9486 - val_loss: 0.1484 - val_acc: 0.9479\n",
      "Epoch 34/200\n",
      "0s - loss: 0.1522 - acc: 0.9486 - val_loss: 0.1452 - val_acc: 0.9483\n",
      "Epoch 35/200\n",
      "0s - loss: 0.1486 - acc: 0.9518 - val_loss: 0.1420 - val_acc: 0.9535\n",
      "Epoch 36/200\n",
      "0s - loss: 0.1455 - acc: 0.9518 - val_loss: 0.1391 - val_acc: 0.9571\n",
      "Epoch 37/200\n",
      "0s - loss: 0.1434 - acc: 0.9582 - val_loss: 0.1366 - val_acc: 0.9575\n",
      "Epoch 38/200\n",
      "0s - loss: 0.1402 - acc: 0.9582 - val_loss: 0.1355 - val_acc: 0.9555\n",
      "Epoch 39/200\n",
      "0s - loss: 0.1390 - acc: 0.9518 - val_loss: 0.1344 - val_acc: 0.9563\n",
      "Epoch 40/200\n",
      "0s - loss: 0.1381 - acc: 0.9550 - val_loss: 0.1316 - val_acc: 0.9575\n",
      "Epoch 41/200\n",
      "0s - loss: 0.1352 - acc: 0.9582 - val_loss: 0.1285 - val_acc: 0.9587\n",
      "Epoch 42/200\n",
      "0s - loss: 0.1327 - acc: 0.9598 - val_loss: 0.1274 - val_acc: 0.9631\n",
      "Epoch 43/200\n",
      "0s - loss: 0.1322 - acc: 0.9646 - val_loss: 0.1256 - val_acc: 0.9635\n",
      "Epoch 44/200\n",
      "0s - loss: 0.1306 - acc: 0.9614 - val_loss: 0.1241 - val_acc: 0.9615\n",
      "Epoch 45/200\n",
      "0s - loss: 0.1291 - acc: 0.9614 - val_loss: 0.1236 - val_acc: 0.9611\n",
      "Epoch 46/200\n",
      "0s - loss: 0.1286 - acc: 0.9582 - val_loss: 0.1240 - val_acc: 0.9599\n",
      "Epoch 47/200\n",
      "0s - loss: 0.1284 - acc: 0.9582 - val_loss: 0.1213 - val_acc: 0.9619\n",
      "Epoch 48/200\n",
      "0s - loss: 0.1259 - acc: 0.9630 - val_loss: 0.1198 - val_acc: 0.9679\n",
      "Epoch 49/200\n",
      "0s - loss: 0.1256 - acc: 0.9711 - val_loss: 0.1195 - val_acc: 0.9711\n",
      "Epoch 50/200\n",
      "0s - loss: 0.1252 - acc: 0.9743 - val_loss: 0.1178 - val_acc: 0.9671\n",
      "Epoch 51/200\n",
      "0s - loss: 0.1230 - acc: 0.9695 - val_loss: 0.1208 - val_acc: 0.9615\n",
      "Epoch 52/200\n",
      "0s - loss: 0.1256 - acc: 0.9598 - val_loss: 0.1231 - val_acc: 0.9607\n",
      "Epoch 53/200\n",
      "0s - loss: 0.1276 - acc: 0.9582 - val_loss: 0.1163 - val_acc: 0.9671\n",
      "Epoch 54/200\n",
      "0s - loss: 0.1239 - acc: 0.9711 - val_loss: 0.1163 - val_acc: 0.9747\n",
      "Epoch 55/200\n",
      "0s - loss: 0.1238 - acc: 0.9775 - val_loss: 0.1139 - val_acc: 0.9731\n",
      "Epoch 56/200\n",
      "0s - loss: 0.1204 - acc: 0.9759 - val_loss: 0.1151 - val_acc: 0.9679\n",
      "Epoch 57/200\n",
      "0s - loss: 0.1213 - acc: 0.9695 - val_loss: 0.1203 - val_acc: 0.9623\n",
      "Epoch 58/200\n",
      "0s - loss: 0.1256 - acc: 0.9630 - val_loss: 0.1155 - val_acc: 0.9671\n",
      "Epoch 59/200\n",
      "0s - loss: 0.1204 - acc: 0.9695 - val_loss: 0.1120 - val_acc: 0.9751\n",
      "Epoch 60/200\n",
      "0s - loss: 0.1221 - acc: 0.9775 - val_loss: 0.1149 - val_acc: 0.9767\n",
      "Epoch 61/200\n",
      "0s - loss: 0.1237 - acc: 0.9775 - val_loss: 0.1103 - val_acc: 0.9731\n",
      "Epoch 62/200\n",
      "0s - loss: 0.1175 - acc: 0.9759 - val_loss: 0.1142 - val_acc: 0.9687\n",
      "Epoch 63/200\n",
      "0s - loss: 0.1210 - acc: 0.9727 - val_loss: 0.1166 - val_acc: 0.9671\n",
      "Epoch 64/200\n",
      "0s - loss: 0.1225 - acc: 0.9727 - val_loss: 0.1109 - val_acc: 0.9723\n",
      "Epoch 65/200\n",
      "0s - loss: 0.1169 - acc: 0.9743 - val_loss: 0.1107 - val_acc: 0.9767\n",
      "Epoch 66/200\n",
      "0s - loss: 0.1222 - acc: 0.9775 - val_loss: 0.1138 - val_acc: 0.9771\n",
      "Epoch 67/200\n",
      "0s - loss: 0.1226 - acc: 0.9775 - val_loss: 0.1086 - val_acc: 0.9731\n",
      "Epoch 68/200\n",
      "0s - loss: 0.1172 - acc: 0.9759 - val_loss: 0.1157 - val_acc: 0.9679\n",
      "Epoch 69/200\n",
      "0s - loss: 0.1228 - acc: 0.9695 - val_loss: 0.1128 - val_acc: 0.9707\n",
      "Epoch 70/200\n",
      "0s - loss: 0.1203 - acc: 0.9727 - val_loss: 0.1072 - val_acc: 0.9755\n",
      "Epoch 71/200\n",
      "0s - loss: 0.1175 - acc: 0.9775 - val_loss: 0.1075 - val_acc: 0.9763\n",
      "Epoch 72/200\n",
      "0s - loss: 0.1170 - acc: 0.9775 - val_loss: 0.1071 - val_acc: 0.9747\n",
      "Epoch 73/200\n",
      "0s - loss: 0.1170 - acc: 0.9775 - val_loss: 0.1087 - val_acc: 0.9731\n",
      "Epoch 74/200\n",
      "0s - loss: 0.1170 - acc: 0.9759 - val_loss: 0.1066 - val_acc: 0.9751\n",
      "Epoch 75/200\n",
      "0s - loss: 0.1155 - acc: 0.9775 - val_loss: 0.1067 - val_acc: 0.9771\n",
      "Epoch 76/200\n",
      "0s - loss: 0.1168 - acc: 0.9775 - val_loss: 0.1089 - val_acc: 0.9775\n",
      "Epoch 77/200\n",
      "0s - loss: 0.1197 - acc: 0.9775 - val_loss: 0.1058 - val_acc: 0.9759\n",
      "Epoch 78/200\n",
      "0s - loss: 0.1151 - acc: 0.9775 - val_loss: 0.1111 - val_acc: 0.9723\n",
      "Epoch 79/200\n",
      "0s - loss: 0.1197 - acc: 0.9743 - val_loss: 0.1146 - val_acc: 0.9711\n",
      "Epoch 80/200\n",
      "0s - loss: 0.1219 - acc: 0.9727 - val_loss: 0.1081 - val_acc: 0.9731\n",
      "Epoch 81/200\n",
      "0s - loss: 0.1165 - acc: 0.9775 - val_loss: 0.1052 - val_acc: 0.9771\n",
      "Epoch 82/200\n",
      "0s - loss: 0.1161 - acc: 0.9775 - val_loss: 0.1074 - val_acc: 0.9779\n",
      "Epoch 83/200\n",
      "0s - loss: 0.1187 - acc: 0.9775 - val_loss: 0.1046 - val_acc: 0.9767\n",
      "Epoch 84/200\n",
      "0s - loss: 0.1142 - acc: 0.9775 - val_loss: 0.1106 - val_acc: 0.9727\n",
      "Epoch 85/200\n",
      "0s - loss: 0.1194 - acc: 0.9759 - val_loss: 0.1159 - val_acc: 0.9715\n",
      "Epoch 86/200\n",
      "0s - loss: 0.1234 - acc: 0.9743 - val_loss: 0.1093 - val_acc: 0.9731\n",
      "Epoch 87/200\n",
      "0s - loss: 0.1164 - acc: 0.9759 - val_loss: 0.1049 - val_acc: 0.9775\n",
      "Epoch 88/200\n",
      "0s - loss: 0.1159 - acc: 0.9775 - val_loss: 0.1192 - val_acc: 0.9783\n",
      "Epoch 89/200\n",
      "0s - loss: 0.1317 - acc: 0.9775 - val_loss: 0.1046 - val_acc: 0.9775\n",
      "Epoch 90/200\n",
      "0s - loss: 0.1168 - acc: 0.9775 - val_loss: 0.1120 - val_acc: 0.9723\n",
      "Epoch 91/200\n",
      "0s - loss: 0.1220 - acc: 0.9759 - val_loss: 0.1154 - val_acc: 0.9723\n",
      "Epoch 92/200\n",
      "0s - loss: 0.1230 - acc: 0.9743 - val_loss: 0.1060 - val_acc: 0.9755\n",
      "Epoch 93/200\n",
      "0s - loss: 0.1161 - acc: 0.9775 - val_loss: 0.1043 - val_acc: 0.9775\n",
      "Epoch 94/200\n",
      "0s - loss: 0.1160 - acc: 0.9775 - val_loss: 0.1066 - val_acc: 0.9787\n",
      "Epoch 95/200\n",
      "0s - loss: 0.1190 - acc: 0.9775 - val_loss: 0.1040 - val_acc: 0.9775\n",
      "Epoch 96/200\n",
      "0s - loss: 0.1153 - acc: 0.9775 - val_loss: 0.1054 - val_acc: 0.9755\n",
      "Epoch 97/200\n",
      "0s - loss: 0.1161 - acc: 0.9775 - val_loss: 0.1087 - val_acc: 0.9735\n",
      "Epoch 98/200\n",
      "0s - loss: 0.1179 - acc: 0.9775 - val_loss: 0.1056 - val_acc: 0.9755\n",
      "Epoch 99/200\n",
      "0s - loss: 0.1151 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9771\n",
      "Epoch 100/200\n",
      "0s - loss: 0.1152 - acc: 0.9775 - val_loss: 0.1062 - val_acc: 0.9787\n",
      "Epoch 101/200\n",
      "0s - loss: 0.1187 - acc: 0.9775 - val_loss: 0.1033 - val_acc: 0.9771\n",
      "Epoch 102/200\n",
      "0s - loss: 0.1147 - acc: 0.9775 - val_loss: 0.1076 - val_acc: 0.9747\n",
      "Epoch 103/200\n",
      "0s - loss: 0.1174 - acc: 0.9775 - val_loss: 0.1106 - val_acc: 0.9731\n",
      "Epoch 104/200\n",
      "0s - loss: 0.1194 - acc: 0.9759 - val_loss: 0.1052 - val_acc: 0.9755\n",
      "Epoch 105/200\n",
      "0s - loss: 0.1155 - acc: 0.9775 - val_loss: 0.1044 - val_acc: 0.9783\n",
      "Epoch 106/200\n",
      "0s - loss: 0.1178 - acc: 0.9775 - val_loss: 0.1044 - val_acc: 0.9783\n",
      "Epoch 107/200\n",
      "0s - loss: 0.1163 - acc: 0.9775 - val_loss: 0.1043 - val_acc: 0.9759\n",
      "Epoch 108/200\n",
      "0s - loss: 0.1171 - acc: 0.9775 - val_loss: 0.1056 - val_acc: 0.9755\n",
      "Epoch 109/200\n",
      "0s - loss: 0.1159 - acc: 0.9775 - val_loss: 0.1030 - val_acc: 0.9771\n",
      "Epoch 110/200\n",
      "0s - loss: 0.1143 - acc: 0.9775 - val_loss: 0.1037 - val_acc: 0.9779\n",
      "Epoch 111/200\n",
      "0s - loss: 0.1159 - acc: 0.9775 - val_loss: 0.1039 - val_acc: 0.9783\n",
      "Epoch 112/200\n",
      "0s - loss: 0.1164 - acc: 0.9775 - val_loss: 0.1030 - val_acc: 0.9771\n",
      "Epoch 113/200\n",
      "0s - loss: 0.1152 - acc: 0.9775 - val_loss: 0.1029 - val_acc: 0.9771\n",
      "Epoch 114/200\n",
      "0s - loss: 0.1145 - acc: 0.9775 - val_loss: 0.1029 - val_acc: 0.9771\n",
      "Epoch 115/200\n",
      "0s - loss: 0.1151 - acc: 0.9775 - val_loss: 0.1029 - val_acc: 0.9771\n",
      "Epoch 116/200\n",
      "0s - loss: 0.1147 - acc: 0.9775 - val_loss: 0.1032 - val_acc: 0.9775\n",
      "Epoch 117/200\n",
      "0s - loss: 0.1152 - acc: 0.9775 - val_loss: 0.1029 - val_acc: 0.9771\n",
      "Epoch 118/200\n",
      "0s - loss: 0.1142 - acc: 0.9775 - val_loss: 0.1043 - val_acc: 0.9759\n",
      "Epoch 119/200\n",
      "0s - loss: 0.1152 - acc: 0.9775 - val_loss: 0.1049 - val_acc: 0.9755\n",
      "Epoch 120/200\n",
      "0s - loss: 0.1149 - acc: 0.9775 - val_loss: 0.1031 - val_acc: 0.9775\n",
      "Epoch 121/200\n",
      "0s - loss: 0.1145 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9775\n",
      "Epoch 122/200\n",
      "0s - loss: 0.1153 - acc: 0.9775 - val_loss: 0.1032 - val_acc: 0.9771\n",
      "Epoch 123/200\n",
      "0s - loss: 0.1145 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9771\n",
      "Epoch 124/200\n",
      "0s - loss: 0.1141 - acc: 0.9775 - val_loss: 0.1050 - val_acc: 0.9755\n",
      "Epoch 125/200\n",
      "0s - loss: 0.1153 - acc: 0.9775 - val_loss: 0.1058 - val_acc: 0.9755\n",
      "Epoch 126/200\n",
      "0s - loss: 0.1152 - acc: 0.9775 - val_loss: 0.1034 - val_acc: 0.9771\n",
      "Epoch 127/200\n",
      "0s - loss: 0.1141 - acc: 0.9775 - val_loss: 0.1099 - val_acc: 0.9787\n",
      "Epoch 128/200\n",
      "0s - loss: 0.1225 - acc: 0.9775 - val_loss: 0.1055 - val_acc: 0.9783\n",
      "Epoch 129/200\n",
      "0s - loss: 0.1167 - acc: 0.9775 - val_loss: 0.1049 - val_acc: 0.9755\n",
      "Epoch 130/200\n",
      "0s - loss: 0.1144 - acc: 0.9775 - val_loss: 0.1115 - val_acc: 0.9731\n",
      "Epoch 131/200\n",
      "0s - loss: 0.1202 - acc: 0.9759 - val_loss: 0.1113 - val_acc: 0.9731\n",
      "Epoch 132/200\n",
      "0s - loss: 0.1189 - acc: 0.9759 - val_loss: 0.1041 - val_acc: 0.9759\n",
      "Epoch 133/200\n",
      "0s - loss: 0.1148 - acc: 0.9775 - val_loss: 0.1053 - val_acc: 0.9783\n",
      "Epoch 134/200\n",
      "0s - loss: 0.1171 - acc: 0.9775 - val_loss: 0.1049 - val_acc: 0.9779\n",
      "Epoch 135/200\n",
      "0s - loss: 0.1163 - acc: 0.9775 - val_loss: 0.1036 - val_acc: 0.9771\n",
      "Epoch 136/200\n",
      "0s - loss: 0.1139 - acc: 0.9775 - val_loss: 0.1058 - val_acc: 0.9755\n",
      "Epoch 137/200\n",
      "0s - loss: 0.1152 - acc: 0.9775 - val_loss: 0.1073 - val_acc: 0.9747\n",
      "Epoch 138/200\n",
      "0s - loss: 0.1164 - acc: 0.9775 - val_loss: 0.1062 - val_acc: 0.9755\n",
      "Epoch 139/200\n",
      "0s - loss: 0.1155 - acc: 0.9775 - val_loss: 0.1044 - val_acc: 0.9759\n",
      "Epoch 140/200\n",
      "0s - loss: 0.1143 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9771\n",
      "Epoch 141/200\n",
      "0s - loss: 0.1139 - acc: 0.9775 - val_loss: 0.1033 - val_acc: 0.9775\n",
      "Epoch 142/200\n",
      "0s - loss: 0.1146 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9771\n",
      "Epoch 143/200\n",
      "0s - loss: 0.1141 - acc: 0.9775 - val_loss: 0.1061 - val_acc: 0.9755\n",
      "Epoch 144/200\n",
      "0s - loss: 0.1155 - acc: 0.9775 - val_loss: 0.1059 - val_acc: 0.9755\n",
      "Epoch 145/200\n",
      "0s - loss: 0.1151 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9771\n",
      "Epoch 146/200\n",
      "0s - loss: 0.1137 - acc: 0.9775 - val_loss: 0.1040 - val_acc: 0.9779\n",
      "Epoch 147/200\n",
      "0s - loss: 0.1157 - acc: 0.9775 - val_loss: 0.1037 - val_acc: 0.9775\n",
      "Epoch 148/200\n",
      "0s - loss: 0.1151 - acc: 0.9775 - val_loss: 0.1038 - val_acc: 0.9767\n",
      "Epoch 149/200\n",
      "0s - loss: 0.1141 - acc: 0.9775 - val_loss: 0.1046 - val_acc: 0.9759\n",
      "Epoch 150/200\n",
      "0s - loss: 0.1143 - acc: 0.9775 - val_loss: 0.1037 - val_acc: 0.9767\n",
      "Epoch 151/200\n",
      "0s - loss: 0.1143 - acc: 0.9775 - val_loss: 0.1037 - val_acc: 0.9771\n",
      "Epoch 152/200\n",
      "0s - loss: 0.1136 - acc: 0.9775 - val_loss: 0.1051 - val_acc: 0.9755\n",
      "Epoch 153/200\n",
      "0s - loss: 0.1146 - acc: 0.9775 - val_loss: 0.1076 - val_acc: 0.9747\n",
      "Epoch 154/200\n",
      "0s - loss: 0.1167 - acc: 0.9775 - val_loss: 0.1077 - val_acc: 0.9747\n",
      "Epoch 155/200\n",
      "0s - loss: 0.1162 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9771\n",
      "Epoch 156/200\n",
      "0s - loss: 0.1128 - acc: 0.9775 - val_loss: 0.1052 - val_acc: 0.9787\n",
      "Epoch 157/200\n",
      "0s - loss: 0.1175 - acc: 0.9775 - val_loss: 0.1073 - val_acc: 0.9787\n",
      "Epoch 158/200\n",
      "0s - loss: 0.1180 - acc: 0.9775 - val_loss: 0.1037 - val_acc: 0.9767\n",
      "Epoch 159/200\n",
      "0s - loss: 0.1144 - acc: 0.9775 - val_loss: 0.1130 - val_acc: 0.9727\n",
      "Epoch 160/200\n",
      "0s - loss: 0.1211 - acc: 0.9759 - val_loss: 0.1122 - val_acc: 0.9731\n",
      "Epoch 161/200\n",
      "0s - loss: 0.1193 - acc: 0.9759 - val_loss: 0.1036 - val_acc: 0.9771\n",
      "Epoch 162/200\n",
      "0s - loss: 0.1130 - acc: 0.9775 - val_loss: 0.1076 - val_acc: 0.9787\n",
      "Epoch 163/200\n",
      "0s - loss: 0.1204 - acc: 0.9775 - val_loss: 0.1069 - val_acc: 0.9787\n",
      "Epoch 164/200\n",
      "0s - loss: 0.1187 - acc: 0.9775 - val_loss: 0.1033 - val_acc: 0.9771\n",
      "Epoch 165/200\n",
      "0s - loss: 0.1152 - acc: 0.9775 - val_loss: 0.1063 - val_acc: 0.9755\n",
      "Epoch 166/200\n",
      "0s - loss: 0.1153 - acc: 0.9775 - val_loss: 0.1035 - val_acc: 0.9771\n",
      "Epoch 167/200\n",
      "0s - loss: 0.1130 - acc: 0.9775 - val_loss: 0.1034 - val_acc: 0.9783\n",
      "Epoch 168/200\n",
      "0s - loss: 0.1161 - acc: 0.9775 - val_loss: 0.1040 - val_acc: 0.9787\n",
      "Epoch 169/200\n",
      "0s - loss: 0.1158 - acc: 0.9775 - val_loss: 0.1031 - val_acc: 0.9771\n",
      "Epoch 170/200\n",
      "0s - loss: 0.1135 - acc: 0.9775 - val_loss: 0.1051 - val_acc: 0.9755\n",
      "Epoch 171/200\n",
      "0s - loss: 0.1147 - acc: 0.9775 - val_loss: 0.1052 - val_acc: 0.9755\n",
      "Epoch 172/200\n",
      "0s - loss: 0.1149 - acc: 0.9775 - val_loss: 0.1046 - val_acc: 0.9759\n",
      "Epoch 173/200\n",
      "0s - loss: 0.1142 - acc: 0.9775 - val_loss: 0.1032 - val_acc: 0.9771\n",
      "Epoch 174/200\n",
      "0s - loss: 0.1130 - acc: 0.9775 - val_loss: 0.1029 - val_acc: 0.9783\n",
      "Epoch 175/200\n",
      "0s - loss: 0.1147 - acc: 0.9775 - val_loss: 0.1046 - val_acc: 0.9787\n",
      "Epoch 176/200\n",
      "0s - loss: 0.1168 - acc: 0.9775 - val_loss: 0.1024 - val_acc: 0.9775\n",
      "Epoch 177/200\n",
      "0s - loss: 0.1141 - acc: 0.9775 - val_loss: 0.1026 - val_acc: 0.9775\n",
      "Epoch 178/200\n",
      "0s - loss: 0.1132 - acc: 0.9775 - val_loss: 0.1024 - val_acc: 0.9775\n",
      "Epoch 179/200\n",
      "0s - loss: 0.1132 - acc: 0.9775 - val_loss: 0.1024 - val_acc: 0.9779\n",
      "Epoch 180/200\n",
      "0s - loss: 0.1142 - acc: 0.9775 - val_loss: 0.1034 - val_acc: 0.9787\n",
      "Epoch 181/200\n",
      "0s - loss: 0.1149 - acc: 0.9775 - val_loss: 0.1025 - val_acc: 0.9775\n",
      "Epoch 182/200\n",
      "0s - loss: 0.1131 - acc: 0.9775 - val_loss: 0.1064 - val_acc: 0.9755\n",
      "Epoch 183/200\n",
      "0s - loss: 0.1156 - acc: 0.9775 - val_loss: 0.1067 - val_acc: 0.9755\n",
      "Epoch 184/200\n",
      "0s - loss: 0.1155 - acc: 0.9775 - val_loss: 0.1032 - val_acc: 0.9771\n",
      "Epoch 185/200\n",
      "0s - loss: 0.1131 - acc: 0.9775 - val_loss: 0.1027 - val_acc: 0.9779\n",
      "Epoch 186/200\n",
      "0s - loss: 0.1137 - acc: 0.9775 - val_loss: 0.1032 - val_acc: 0.9783\n",
      "Epoch 187/200\n",
      "0s - loss: 0.1142 - acc: 0.9775 - val_loss: 0.1025 - val_acc: 0.9771\n",
      "Epoch 188/200\n",
      "0s - loss: 0.1132 - acc: 0.9775 - val_loss: 0.1034 - val_acc: 0.9771\n",
      "Epoch 189/200\n",
      "0s - loss: 0.1131 - acc: 0.9775 - val_loss: 0.1034 - val_acc: 0.9771\n",
      "Epoch 190/200\n",
      "0s - loss: 0.1130 - acc: 0.9775 - val_loss: 0.1027 - val_acc: 0.9775\n",
      "Epoch 191/200\n",
      "0s - loss: 0.1130 - acc: 0.9775 - val_loss: 0.1030 - val_acc: 0.9775\n",
      "Epoch 192/200\n",
      "0s - loss: 0.1135 - acc: 0.9775 - val_loss: 0.1028 - val_acc: 0.9771\n",
      "Epoch 193/200\n",
      "0s - loss: 0.1130 - acc: 0.9775 - val_loss: 0.1034 - val_acc: 0.9771\n",
      "Epoch 194/200\n",
      "0s - loss: 0.1129 - acc: 0.9775 - val_loss: 0.1032 - val_acc: 0.9771\n",
      "Epoch 195/200\n",
      "0s - loss: 0.1125 - acc: 0.9775 - val_loss: 0.1034 - val_acc: 0.9775\n",
      "Epoch 196/200\n",
      "0s - loss: 0.1146 - acc: 0.9775 - val_loss: 0.1044 - val_acc: 0.9783\n",
      "Epoch 197/200\n",
      "0s - loss: 0.1162 - acc: 0.9775 - val_loss: 0.1031 - val_acc: 0.9771\n",
      "Epoch 198/200\n",
      "0s - loss: 0.1129 - acc: 0.9775 - val_loss: 0.1032 - val_acc: 0.9775\n",
      "Epoch 199/200\n",
      "0s - loss: 0.1125 - acc: 0.9775 - val_loss: 0.1044 - val_acc: 0.9759\n",
      "Epoch 200/200\n",
      "0s - loss: 0.1136 - acc: 0.9775 - val_loss: 0.1042 - val_acc: 0.9759\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xt8VOW97/HPL5OQG+GaACEBAoiC\nctWI7nopWmvBKnihFrenVreW1ku91PYUT/ex6q67d+1x17birm1ttWqxKu3GeiuKdwnKHRFElBAu\n4U4gIcnM7/wxkzCEySREVhKY7/v1mtfMWutZa36zMlm/eZ5nrWeZuyMiIgKQ1tEBiIhI56GkICIi\njZQURESkkZKCiIg0UlIQEZFGSgoiItJISUFSnpmFzKzKzAYGtP0hZlYVxLZFDjclBTnixA7gDY+I\nmVXHTV9+qNtz97C7d3X3T9oQyzFmdtDFPmb2JzO7I7b9Ne7etRXbusbMXj7UGEQOp/SODkDkUMUf\nYM1sLXCNu7/YXHkzS3f3+vaIrSOlyueUYKmmIEcdM/uBmT1uZn82s93A/zKzfzGzt8xsh5ltMLP7\nzCwjVj7dzNzMSmLTf4otf9bMdpvZm2Y2+FPEc0BtwsyuNrO1sW2vMbNpZjYK+CVwRqzGsyVWtkcs\nnsrYOreZmcWWXWNm82KxbgN+EPt8I+Leq9DM9ppZ77bGL6lFSUGOVhcBjwLdgceBeuAmIB84DZgI\nfD3J+v8K/F+gF/AJ8B+HIygz6wbcA3ze3fNisSx29yXADcCrsaas/NgqvwJygCHA2cDVwBVxm/wM\nsAIoAO4EngD+V5PP8Zy7bz0c8cvRT0lBjlavufvf3D3i7tXuPt/d33b3endfA8wEPptk/VnuXubu\ndcAjwNhkbxb7hd74AC5NUtyBkWaW5e4b3H15M9vMiG1nhrvvjsV9L/CVuGKfuPuvY/0i1cAfgH9t\nqE3Eyv4xWewi8ZQU5Gi1Ln7CzIab2f+Y2UYz2wXcRbTW0JyNca/3Akk7it29R/yD6C/2ROV2AZcB\n1wMbzezvZnZsM5vtA4SAj+PmfQwUxU0f8Dnd/XWitaLTzWwkMBD4n2Sxi8RTUpCjVdMzgh4AlgLH\nuHs34HbADlqrHbj7s+5+DlAIrI7FBgfHvBkIA4Pi5g0E1sdvLsFbPEy0CekrwBPuvu9wxC2pQUlB\nUkUesBPYE+uITdafEJhYx+8FZpYD1AJ7iB74ATYBxQ0d4LGmq1nAf5pZ11hn9y3An1p4mz8CU4n2\nJzwcwMeQo5iSgqSKW4GvAruJ/jJ/vIPiCAHfATYAW4l2FN8QW/YCsArYZGYNzVfXEU0eHwGvEO0z\nSHqgd/e1wBKg1t3fOMzxy1HOdJMdkaOPmT0MrHH3Ozo6Fjmy6OI1kaOMmQ0BpgCjOjoWOfKo+Ujk\nKGJmPwQWAf/ZlmE7RNR8JCIijVRTEBGRRkdcn0J+fr6XlJR0dBgiIkeUBQsWbHH3gpbKBZYUzOwh\n4Hxgs7uPTLDcgP8HnEf0itEr3f3dlrZbUlJCWVnZ4Q5XROSoZmYft1wq2Oaj3xMddKw5k4Bhscd0\n4NcBxiIiIq0QWFJw93nAtiRFpgAPe9RbQA8zKwwqHhERaVlHdjQXceBgXuUcONBXIzObbmZlZlZW\nWVnZLsGJiKSijkwKiQYjS3h+rLvPdPdSdy8tKGixn0RERNqoI5NCOTAgbroYqOigWEREhI5NCrOB\nKyzqVGCnu2/owHhERFJekKek/hmYAOSbWTnwfaBhSODfAHOIno66mugpqVcFFYuIiLROYEnB3S9r\nYbkTvfuUHGF2VtcRSjO6Zib++mzYWc3umnryu2bSK7fLwQXc2bRtGzvru5CXlU5h9+wmi52Ptuyh\nPhLtYspMT2Ngrxzc4ZP16/G9Wwln9iCS3QuAvt2y6J6d0bh+5ZYt7N3wPhauZV/+CXhGzsHvU7WZ\n+vXvsXVTBbV5RdT0GUeXrBwG9sqh4U6WVTsq2fn+PLrsWEVd98FUF55COLt3k88SIXPLMrIr3qKu\n2wD2Fp2Od4nepC03M52iHtnUbS9n26I54GFq8kexr8+YxtXTaraTsXs96Xs2EqrZTm3PodR2KwFr\n/v4/kcwe+5eHa+my8yPcQhDKwNMy8LQuhLN6QlqocZ30qgpyPnmZUM02wtm9qRo8kUhWT9LMKOmd\nQ3oo2mhQs34Z2z98h3BuX+pz+1HXtRjPyE4UBriTtm8H6XsriXTpSn1OH0jb/51Iq9lOlx1rsPA+\n6nP7UZ9beOC23LH6ajw9+6DPa3V7yal4k6zNC8Ej7Os1nD2DzsEzsunXPYtuWRkQrsPXvc2O9+cR\nqauhPrcfewZ8lvpuA6PbqK8ma9O7ZG77gLTaXdT2PJa9xacT6ZJ30OdI311OVuUi0qsqSKvfx77e\nI6jP7YuFa7FILRauw+qrydi1Dsyo6TOWmj5j9+9jj5C+ZyPpVRtI37MBi9RTkz+KSFYP8Ah4GPMI\nuINHMCIQCUf3AZHGMqHqbaTv2UhdjyHU5/bD6vZS120QhKLf7z55mfTISfA/dRgdcVc0S/B27q2j\nYmc1Iwq7HbigZidbFjzDv/0zjRU1vfiXofn87Euj6ZOXFV3+4T/Z/MIvYMMS/lZ/Ng9EJjOiqDfT\nzxzKeaP6YXXV7P7rTeS8/yR9CfNe+GRuq7uangWFfO+8EXzu2F7Uzf0JaxY8T92eHbwTGc4rkTF8\nECnmktxFnBuex2g+ACDixiIfyj31U3kv40SuO2soXz6pmNV//zlj3r+XAqsDoN7T+GP48/yo/jKK\nCnoy4dg+nFX7MuOX3kmm19A39tHejwxgau0MQt0Kubx4C1/c8ScGbHudosb730S39XpkJE+HT2MT\nPTk3rYwvhMootP1nXld7F54On8bT4dPZSS435jzP5+tfoa/t386yyCDWeR8G2waOSSs/5L/PNu/K\n+5GBVJHNyWkr6WlVCcu8ExlBDRmMsE8Y0uR99s79dx4PT+C34fPYnVnIRb0/4YLdT3BS7TvEnxde\n5yHKIsexxAez3fPoZ1spti0UWyXFVkmu7b+p207P4Z3ICPaQybG2nuPTDr5WaqvnUe4FdKWafraN\nXNtHuefzVuR41kQKqSKLoVbBJaFX6Wo1B6y7y3O4s+4KnuZMpvSp5NtVP6V/fTk9m7zHh5FCttKN\nMfYhmVZ/wLI6D7HAj2Wr55FFHTns45i0cgpsV+t2fpxN3oO3IyNIJ8zJaSspsJ2HvI3W2OXZrPBB\nRDyNipO/zoTJVwbyPg2OuAHxSktLXVc0B6S+ltdm/zf/sbg7K2t6MGPScL5+5pDoL+dIhNo/XUqX\nNS8AsKznOVy25SoG9enBY9NPJXfXGvyBM9lYn8OmjGLG1i2iMvdYbrVbmbclj1F5VdxTfzdDI5/w\nWORsSgr7cGrlLKq79OSWjNtZtKMLT/d9iMKtb7EwMpRePXtStHsJocj+g876zKFsG3Qe4W4DyN5T\nTvEnz5C752OWZpfy+u6+nJm2mBFp61iUfQp1Y76CWxp9NrzMoLVPUJXZjyWhEXTd8zGjbA3v2fG8\nPfg6hpQMpmD3cka9+33qQtlssnxK9q1ki3fj7bxz6T7uQvZ0H0bXqo/ou2Eu/df9nZy90bthhkNZ\nVPY9g42FZ7O14F/I2fMxRev+TtG6vxEKRw9otZbJ/F7ns3f0FaRl5tFvw0v0W/88XfZtZ19WAZV9\nPsPergOpye5HXUYeebtWkVWzudk/kUXC5O1aRdfdH5Jet5td3Yezud8E3NJIi9SRFqklFNlH9+1L\n6bFtEeYRqnOK2NzvDCr7nsne3AF03b2GktUPU7Tu76R5HRGMNJxd1p13C79EZPgFZNftJKt6E912\nrSR/0xt03b2aUKSWuoxu7M3pT3VOEdU5RezNLaI2szfpdVX02L6Entvei/5Kzu5HZZ/PsLv7cYRD\nWWRVbyKrZhPZe9aTs3c99Rldqc7uR22XnvTYsYweW98ja9+W6H5Ny2BD8XmsHzCZbfknE0kL0XvL\nfIat+CW9t5RRE+pKVriKrWm9md33evJGTiI7ryc5VWvps3EeBZteJaN2F9vyS9mWfzI7eo6kPqMr\nPbYtpmDTq+RvfoNQuIZIKJNwKIu9uQPY0XMMO3qNYk/XEtzS6LZjBRm1u/C0DCINj1AXqnOKsEgd\nvbaU0b/8WfJ2fYCbsbPHSLbll1KTXUh1dj8wo/uOZYTqq3FLAwy3UPS1GU4aWBre8CA6vy6jOzXZ\nfcjbtYqM2h1E0rrQa+u75FZ9FN03p1xHn5MvadO/t5ktcPfSFsspKQgAH79J1RPT6brnE/ZYLo/2\n+RZ3fzyC704czrUThsIb/wXP/zv31k9l2ol9KFz8K7YUfpYz1l7F6cMKeKD2/1C1aS3n1/+YP9w0\nmcFbXoGnr8U9wup+X6T3+n+SE9nNq2N/xogzLqK4Zw5ULIRHv0ykbi/79tUS8jp+lP4NTpt6E58b\n0RfqqmHt61C5AoZ+Dvoef2DMdTXw+i9g6ZP4llVszBvJqgFf4rRLvkkoFHcOxYdz4e0HYONiwt2K\n2DloIj3P+iaWHlcNX78AXvkJ1NcQ7n8SG074OkX9+jQ2JTVyh3XvQPU2GPxZ6JJz8L6s2QUfvQK7\nNsDISyC398FlOoNdFbD4cajdA90HwKgvJf48AJEI1O2BzLzEyw+HfVVQvw8yshPHEQnD/N/ClpWQ\n1w9Kr4acXsHFc5RRUpD9dlWw+f03eGnxRxxzynmcPOqEA5eXlxH5wwWU1+XxZN5XuLn7K1j5fP6c\n/03u3HQar19cR6/ZV/Kin8Qzw37ELy8/Ccp+B3+/hY29Slm7pYpT01YwvfYWvnjp15gyNnYN4va1\n8I/bogflzK5w+SzoP/bA996+Fv5yFXvzSnipzxV87owzyOnShlbNcD2E1Boq0hwlBQGgdskzpD1z\nLen1e4BoW/za0EB2p3Uno/8ohudnwJK/sLE+j2nhO3j4xsmU9MiAv1wJK/+Hd3wEY9I+YmduCRO2\n/G8eue5sxg2MteIuehyevpZ60rh139cYfu410VpFU3U10Q65UMbBy0SkXbQ2Kein1ZGsZie8di8V\nHyzgw827eSlyEicMGcjUAbsIb1hK9ccLyKurZGFkCDNzv8F3vjiKbWV/JbR5Gdm1Wxn48V+o+dh4\nIVLKA+mX8/N/+wIl+bnRbX/p9zD3BwxY8jJl24dy85brGT6w3/6EADDmy9BzEKGMbL6dOYwBvZpp\nesjICnxXiMjhoZrCEaruw1fxJ68hY+9mlkUG0iujlv7h6AXhYdJYSxGLwwOpLRxPvwlXc8qw/mRl\n7D9F0d3557IK5n9UiWVkcdnJAxnY++CDuruzdP0uXv9wC589tuDgM5JE5Iig5qMjWX0tbFvDknVb\n2VpVTZqHsUg95hHMw6TvWMO4pf/Jukg+t9RdR7hwHI9PP5XcHSv5xfPv8+vl6ZwwsIDbzz/+wF/2\nIpKylBSOVOsXwJNfg20fJi22InQsa879Pbk9Cji5pBe5sQvJwhFnecUuRhZ1O/jMGRFJWepTOBK9\n+0f4+82Ec/pwJ98gt1svrjhtKG7pkBaKXrWalg6hDIYddyojMg++0jSUZowq7t4BwYvI0UBJoT3U\n1cCu9dHz7utrAIt2vqZnQaQednwSPV98yV/wIWfz9b3X8cauMHOuOIPCho5fEZF2oKQQtL3bYOYE\n2NHC7VEzu8FnbuS3Xb7Ci/9YxY8vGbX/TCARkXaipBCkSBievg52b4Av3sPOtO7UWmZsILAarL4a\n0tIJ5+RT0+8k/rpkG/e/sJpzj+/LpaUDWt6+iMhhpqQQhKpKePRSqHgPcJj0E/4a+gK3/mUR+/v1\nc2MPgHrgbQC+OKqQuy8aqU5iEekQSgqHW/UO+NNFsGU1nPEt6HM8O4dO5u6fv8Lo4h585dRBza46\nrE9Xxgzo0Y7BiogcSEnhcPufW2HzCrjscRh2Du7Oz2cvY9veWv7wb+MZWaQzg0Sk8+rI23EeefZV\nwe5NzS//4DlYOgvO/A4MO4f6cITbn1nGw29+zFf/pUQJQUQ6PdUUWquqEn43CfbtgpsWHzyeT31t\ntJZQMAJO/xa7a+q44dH3eOWDSr7+2SF89wvDOyZuEZFDEGhNwcwmmtlKM1ttZjMSLB9kZi+Z2WIz\ne9nMioOMp832VcGfLobtH0HVJljyl4PLLH8Gdq6Dz9/Fzjrj0gfe4vXVW/jhxaO4bdII0tLUcSwi\nnV9gScHMQsD9wCTgeOAyM2tylxR+Bjzs7qOBu4AfBhXPp/LiHbBxCVz2GPQdSfjNX0HT4UHeeQB6\nDaV28Nl8448LWLVpN//91VIuGz+wQ0IWEWmLIJuPxgOr3X0NgJk9BkwBlseVOR64JfZ6LvB0YNFs\nXgEbFh/6ens2w/wH4dTr8GPO4dX3lnLm8jv48L+vZOjJXwALwd4tUD4fJv6YB+Z9xJtrtnLPpWOY\ncFyfw/85REQCFGRSKALWxU2XA6c0KbMIuAT4f8BFQJ6Z9Xb3rYc9mlXPwwu3t23dghFw9v/l3hdX\n8Zt3B/PTLqdz7vpnYX1cDsvqwb5RX+YP9y7grOMKuPjEztkSJiKSTJBJIVEjetMhWb8N/NLMrgTm\nAeuJXsl14IbMpgPTAQYObGNzzIlXwPDz27Zu92Le/LiK//rnKi46sYTQ8AcZ8+g7/PaiQs44Jj9a\nJqcXs5dVsaVqH1efPqRt7yMi0sGCTArlQPxYDcVARXwBd68ALgYws67AJe6+s+mG3H0mMBOiQ2e3\nKZrsnpDdk/96aRWLyncc4srbWLhuByW9c/nBhSPpEkrjhz26MWPuHka8n9ZYZnH5To7rm8dpx3TS\nG7WLiLQgyKQwHxhmZoOJ1gCmAf8aX8DM8oFt7h4BbgMeCjAeAB58dQ3poTQKux/aLSIH5+fy/QtO\naLyp/IxJw3lg3ods2FnTWKZvtyxuPmeYhqgQkSNWYEnB3evN7AbgOSAEPOTuy8zsLqDM3WcDE4Af\nmpkTbT66Pqh49scFF44t4vYLmp4IdWguGNOfC8b0P0xRiYh0DoFevObuc4A5TebdHvd6FjAryBia\nirijSwZERBJLuWEuIo4uJBMRaUbKJYWwO2lq8xcRSSjlkoKr+UhEpFkplxQijmoKIiLNSMGkoJqC\niEhzUiopuDuujmYRkWalVFKIxK6FVvORiEhiKZYUollBFQURkcRSMiloGAoRkcRSKylEos8hVRVE\nRBJKraSg5iMRkaRSNCkoK4iIJJJiSSH6rKQgIpJYaiWFiJqPRESSSa2k0NB8pKwgIpJQiiWF6LNO\nSRURSSzFkkI0K4SUFEREEkrJpKDWIxGRxAJNCmY20cxWmtlqM5uRYPlAM5trZu+Z2WIzOy/IeHT2\nkYhIcoElBTMLAfcDk4DjgcvM7Pgmxf4deMLdxwHTgF8FFQ/sP/tIOUFEJLEgawrjgdXuvsbda4HH\ngClNyjjQLfa6O1ARYDz7+xTUfiQiklB6gNsuAtbFTZcDpzQpcwfwvJl9E8gFzgkwHjUfiYi0IMia\nQqIjrzeZvgz4vbsXA+cBfzSzg2Iys+lmVmZmZZWVlW0OaP8oqW3ehIjIUS3IpFAODIibLubg5qGr\ngScA3P1NIAvIb7ohd5/p7qXuXlpQUNDmgFxjH4mIJBVkUpgPDDOzwWbWhWhH8uwmZT4BPgdgZiOI\nJoW2VwVaENbQ2SIiSQWWFNy9HrgBeA5YQfQso2VmdpeZTY4VuxX4mpktAv4MXOkNP+cDoOsURESS\nC7KjGXefA8xpMu/2uNfLgdOCjCGe7rwmIpJcSl3R7Dr7SEQkqZRKCuFIw3UKHRyIiEgnlVKHRzUf\niYgkl2JJIfqs5iMRkcRSKim4zj4SEUkqpZJCY5+CagoiIgmlVFLQnddERJJLqaSg5iMRkeRSKik0\ndjQrK4iIJJRSSSGsAfFERJJKqaSgsY9ERJJLqaSgobNFRJJLqaQQiQ2draQgIpJYSiWFxj6FlPrU\nIiKtl1KHRzUfiYgkl1JJQWMfiYgkl2JJQWcfiYgkk1JJoWHsI128JiKSWKBJwcwmmtlKM1ttZjMS\nLL/XzBbGHh+Y2Y4g49Gd10REkgvsHs1mFgLuBz4PlAPzzWx27L7MALj7LXHlvwmMCyoeUPORiEhL\ngqwpjAdWu/sad68FHgOmJCl/GfDnAONRR7OISAuCTApFwLq46fLYvIOY2SBgMPDPAOMhoj4FEZGk\ngkwKiY683kzZacAsdw8n3JDZdDMrM7OyysrKNgek5iMRkeSCTArlwIC46WKgopmy00jSdOTuM929\n1N1LCwoK2hyQmo9ERJILMinMB4aZ2WAz60L0wD+7aSEzOw7oCbwZYCzA/pqCcoKISGKBJQV3rwdu\nAJ4DVgBPuPsyM7vLzCbHFb0MeMwbxqAIUENS0D2aRUQSC+yUVAB3nwPMaTLv9ibTdwQZQ7zGjmYl\nBRGRhFLqimb1KYiIJJdiSSHWp5BSn1pEpPVS6vCoPgURkeRSLClEn9V8JCKSWIolBZ2SKiKSTGol\nBZ19JCKSVGolhVjzUUjjXIiIJJRiSUFjH4mIJJNiSSH6bGo+EhFJKLWSQsRVSxARSSK1koK7+hNE\nRJJIsaSgpiMRkWRalRTM7CIz6x433cPMLgwurGC4q/lIRCSZ1tYUvu/uOxsm3H0H8P1gQgpOOOIa\n4kJEJInWJoVE5QIddjsIEdeFayIiybQ2KZSZ2T1mNtTMhpjZvcCCIAMLQsRdQ1yIiCTR2qTwTaAW\neBx4AqgGrg8qqKC4O2nqVBARaVarmoDcfQ8wI+BYAhd29SmIiCTT2rOPXjCzHnHTPc3suVasN9HM\nVprZajNLmFTM7FIzW25my8zs0daHfuh0SqqISHKt7SzOj51xBIC7bzezPslWMLMQcD/weaAcmG9m\ns919eVyZYcBtwGmt2eanpVNSRUSSa22fQsTMBjZMmFkJ4C2sMx5Y7e5r3L0WeAyY0qTM14D73X07\ngLtvbmU8bRKJ6OwjEZFkWltT+B7wmpm9Eps+E5jewjpFwLq46XLglCZljgUws9eBEHCHu/+jlTEd\nsrCGuRARSaq1Hc3/MLNSoolgIfAM0TOQkkl09G1au0gHhgETgGLgVTMbGd9UBWBm02PvzcCBA2kr\nnZIqIpJcq5KCmV0D3ET0wL0QOBV4Ezg7yWrlwIC46WKgIkGZt9y9DvjIzFYSTRLz4wu5+0xgJkBp\naWlLzVbNcl28JiKSVGv7FG4CTgY+dvezgHFAZQvrzAeGmdlgM+sCTANmNynzNHAWgJnlE21OWtPK\nmA5ZRB3NIiJJtTYp1Lh7DYCZZbr7+8BxyVZw93rgBuA5YAXwhLsvM7O7zGxyrNhzwFYzWw7MBb7j\n7lvb8kFaIxzRxWsiIsm0tqO5PHadwtPAC2a2nYObgg7i7nOAOU3m3R732oFvxR6BU/ORiEhyre1o\nvij28g4zmwt0BwI7Sygoaj4SEUnukEc6dfdXWi7VOUWTgrKCiEhzUurOa2FdvCYiklRKJYXoKKkd\nHYWISOeVUodINR+JiCSXYklBo6SKiCSTYknBCSkniIg0K+WSgpqPRESal1pJQWcfiYgklVpJQaOk\niogklXJJQfdTEBFpXoolBTUfiYgkk2JJQc1HIiLJpFZSiOjsIxGRZFIrKTjqUxARSSLFkoKGzhYR\nSSbFkoKGuRARSSa1kkJENQURkWRSKynoOgURkaQCTQpmNtHMVprZajObkWD5lWZWaWYLY49rgown\nekqqkoKISHMO+XacrWVmIeB+4PNAOTDfzGa7+/ImRR939xuCiiOe6+I1EZGkgqwpjAdWu/sad68F\nHgOmBPh+LQrr7CMRkaSCTApFwLq46fLYvKYuMbPFZjbLzAYk2pCZTTezMjMrq6ysbHNA0fspKCuI\niDQnyKSQ6OjrTab/BpS4+2jgReAPiTbk7jPdvdTdSwsKCtocUCSiU1JFRJIJMimUA/G//IuBivgC\n7r7V3ffFJh8ETgowHlzNRyIiSQWZFOYDw8xssJl1AaYBs+MLmFlh3ORkYEWA8cT6FJQVRESaE9jZ\nR+5eb2Y3AM8BIeAhd19mZncBZe4+G7jRzCYD9cA24Mqg4oHY0NmqKoiINCuwpADg7nOAOU3m3R73\n+jbgtiBjaPLeaj4SEUkixa5o1nUKIiLJpFRSCGvsIxGRpFIqKUTc1acgIpJESiUFDXMhIpJcSiUF\n3WRHRCS5lEoKYd2jWUQkqZRKCq7rFEREkkqppKDmIxGR5FIwKSgriIg0J2WSgrsTcY2SKiKSTAol\nheiz7qcgItK8lEkKkVhWUJ+CiEjzUigpRJ919pGISPNSKCk01BSUFEREmpOCSaGDAxER6cRSKClE\nn1VTEBFpXgolhWhWUE4QEWle6iSFWFUhpPYjEZFmBZoUzGyima00s9VmNiNJualm5mZWGlQsaj4S\nEWlZYEnBzELA/cAk4HjgMjM7PkG5POBG4O2gYgF1NIuItEaQNYXxwGp3X+PutcBjwJQE5f4D+AlQ\nE2AscX0KygoiIs0JMikUAevipstj8xqZ2ThggLv/PdmGzGy6mZWZWVllZWWbgolEos/qUxARaV6Q\nSSHR0dcbF5qlAfcCt7a0IXef6e6l7l5aUFDQpmDUfCQi0rIgk0I5MCBuuhioiJvOA0YCL5vZWuBU\nYHZQnc1qPhIRaVmQSWE+MMzMBptZF2AaMLthobvvdPd8dy9x9xLgLWCyu5cFEUxD85HOPhIRaV5g\nScHd64EbgOeAFcAT7r7MzO4ys8lBvW9zGmoKoZS5MkNE5NClB7lxd58DzGky7/Zmyk4IMhYNiCci\n0rKU+d3ccPGa+hRERJqXQklBZx+JiLQk5ZKCbscpItK81EkKsbOP1HwkItK81EkKaj4SEWlRCiYF\nZQURkeakUFKIPmvsIxGR5gV6nUJnojuviXROdXV1lJeXU1MT6EDJKSMrK4vi4mIyMjLatH7KJAVX\n85FIp1ReXk5eXh4lJSU6EeRTcne2bt1KeXk5gwcPbtM2Uqb5KKyxj0Q6pZqaGnr37q2EcBiYGb17\n9/5Uta6USQqNHc0p84lFjhxKCIfPp92XKXOI1NlHIiItS5mkEMsJSgoicoAdO3bwq1/96pDXO++8\n89ixY0cAEXWslEkK4YguXhMOAdN/AAANKUlEQVSRgzWXFMLhcNL15syZQ48ePYIKq8OkzNlH+/sU\nlBVEOqs7/7aM5RW7Dus2j+/fje9fcEKzy2fMmMGHH37I2LFjycjIoGvXrhQWFrJw4UKWL1/OhRde\nyLp166ipqeGmm25i+vTpAJSUlFBWVkZVVRWTJk3i9NNP54033qCoqIhnnnmG7Ozsw/o52kvK1BTU\nfCQiifzoRz9i6NChLFy4kJ/+9Ke888473H333SxfvhyAhx56iAULFlBWVsZ9993H1q1bD9rGqlWr\nuP7661m2bBk9evTgySefbO+PcdikXk1BOUGk00r2i769jB8//oBz/O+77z6eeuopANatW8eqVavo\n3bv3AesMHjyYsWPHAnDSSSexdu3adov3cEuZpLC/T0FZQUSal5ub2/j65Zdf5sUXX+TNN98kJyeH\nCRMmJLwGIDMzs/F1KBSiurq6XWINQqDNR2Y20cxWmtlqM5uRYPk3zGyJmS00s9fM7PigYomo+UhE\nEsjLy2P37t0Jl+3cuZOePXuSk5PD+++/z1tvvdXO0bW/wGoKZhYC7gc+D5QD881strsvjyv2qLv/\nJlZ+MnAPMDGIeFwXr4lIAr179+a0005j5MiRZGdn07dv38ZlEydO5De/+Q2jR4/muOOO49RTT+3A\nSNtHkM1H44HV7r4GwMweA6YAjUnB3eNPM8gFPKhgVFMQkeY8+uijCednZmby7LPPJlzW0G+Qn5/P\n0qVLG+d/+9vfPuzxtacgk0IRsC5uuhw4pWkhM7se+BbQBTg70YbMbDowHWDgwIFtCiasjmYRkRYF\n2ZiS6PB7UE3A3e9396HAd4F/T7Qhd5/p7qXuXlpQUNCmYDRKqohIy4JMCuXAgLjpYqAiSfnHgAuD\nCkZjH4mItCzIpDAfGGZmg82sCzANmB1fwMyGxU1+EVgVVDARDZ0tItKiwPoU3L3ezG4AngNCwEPu\nvszM7gLK3H02cIOZnQPUAduBrwYVT1h3XhMRaVGgF6+5+xxgTpN5t8e9vinI92/yvoDu0SwikkzK\nnLWvU1JF5HDo2rUrABUVFUydOjVhmQkTJlBWVpZ0O7/4xS/Yu3dv43RnGYo7hZKCTkkVkcOnf//+\nzJo1q83rN00KnWUo7pQZ+ygSaehTUFYQ6bSenQEblxzebfYbBZN+1Ozi7373uwwaNIjrrrsOgDvu\nuAMzY968eWzfvp26ujp+8IMfMGXKlAPWW7t2Leeffz5Lly6lurqaq666iuXLlzNixIgDxj669tpr\nmT9/PtXV1UydOpU777yT++67j4qKCs466yzy8/OZO3du41Dc+fn53HPPPTz00EMAXHPNNdx8882s\nXbu2XYboTqGaQvRZfQoiEm/atGk8/vjjjdNPPPEEV111FU899RTvvvsuc+fO5dZbb23sl0zk17/+\nNTk5OSxevJjvfe97LFiwoHHZ3XffTVlZGYsXL+aVV15h8eLF3HjjjfTv35+5c+cyd+7cA7a1YMEC\nfve73/H222/z1ltv8eCDD/Lee+8B7TNEd+rUFNR8JNL5JflFH5Rx48axefNmKioqqKyspGfPnhQW\nFnLLLbcwb9480tLSWL9+PZs2baJfv34JtzFv3jxuvPFGAEaPHs3o0aMblz3xxBPMnDmT+vp6NmzY\nwPLlyw9Y3tRrr73GRRdd1Dha68UXX8yrr77K5MmT22WI7hRKCtFnNR+JSFNTp05l1qxZbNy4kWnT\npvHII49QWVnJggULyMjIoKSkJOGQ2fESHVs++ugjfvaznzF//nx69uzJlVde2eJ2ktVI2mOI7tRp\nPtI9mkWkGdOmTeOxxx5j1qxZTJ06lZ07d9KnTx8yMjKYO3cuH3/8cdL1zzzzTB555BEAli5dyuLF\niwHYtWsXubm5dO/enU2bNh0wuF5zQ3afeeaZPP300+zdu5c9e/bw1FNPccYZZxzGT5tcCtUUdJ2C\niCR2wgknsHv3boqKiigsLOTyyy/nggsuoLS0lLFjxzJ8+PCk61977bVcddVVjB49mrFjxzJ+/HgA\nxowZw7hx4zjhhBMYMmQIp512WuM606dPZ9KkSRQWFh7Qr3DiiSdy5ZVXNm7jmmuuYdy4ce12NzdL\nVlXpjEpLS72l838TeX7ZRp5ZWME9Xx5DZnoogMhEpC1WrFjBiBEjOjqMo0qifWpmC9y9tKV1U6am\ncO4J/Tj3hMSdRCIiEpUyfQoiItIyJQUR6XBHWjN2Z/Zp96WSgoh0qKysLLZu3arEcBi4O1u3biUr\nK6vN20iZPgUR6ZyKi4spLy+nsrKyo0M5KmRlZVFcXNzm9ZUURKRDZWRkMHjw4I4OQ2LUfCQiIo2U\nFEREpJGSgoiINDrirmg2s0og+UAkzcsHthzGcA6nzhqb4jo0iuvQddbYjra4Brl7QUuFjrik8GmY\nWVlrLvPuCJ01NsV1aBTXoeussaVqXGo+EhGRRkoKIiLSKNWSwsyODiCJzhqb4jo0iuvQddbYUjKu\nlOpTEBGR5FKtpiAiIkkoKYiISKOUSQpmNtHMVprZajOb0YFxDDCzuWa2wsyWmdlNsfl3mNl6M1sY\ne5zXAbGtNbMlsfcvi83rZWYvmNmq2HPPdo7puLh9stDMdpnZzR21v8zsITPbbGZL4+Yl3EcWdV/s\nO7fYzE5s57h+ambvx977KTPrEZtfYmbVcfvuN+0cV7N/OzO7Lba/VprZF4KKK0lsj8fFtdbMFsbm\nt8s+S3J8aL/vmLsf9Q8gBHwIDAG6AIuA4zsolkLgxNjrPOAD4HjgDuDbHbyf1gL5Teb9BJgRez0D\n+HEH/x03AoM6an8BZwInAktb2kfAecCzgAGnAm+3c1znAumx1z+Oi6skvlwH7K+Ef7vY/8EiIBMY\nHPufDbVnbE2W/xy4vT33WZLjQ7t9x1KlpjAeWO3ua9y9FngMmNIRgbj7Bnd/N/Z6N7ACKOqIWFpp\nCvCH2Os/ABd2YCyfAz5097Ze0f6pufs8YFuT2c3toynAwx71FtDDzArbKy53f97d62OTbwFtH0/5\nMMaVxBTgMXff5+4fAauJ/u+2e2xmZsClwJ+Dev9mYmru+NBu37FUSQpFwLq46XI6wYHYzEqAccDb\nsVk3xKqAD7V3M02MA8+b2QIzmx6b19fdN0D0Cwv06YC4GkzjwH/Sjt5fDZrbR53pe/dvRH9RNhhs\nZu+Z2StmdkYHxJPob9eZ9tcZwCZ3XxU3r133WZPjQ7t9x1IlKViCeR16Lq6ZdQWeBG52913Ar4Gh\nwFhgA9Gqa3s7zd1PBCYB15vZmR0QQ0Jm1gWYDPwlNqsz7K+WdIrvnZl9D6gHHonN2gAMdPdxwLeA\nR82sWzuG1NzfrlPsr5jLOPAHSLvuswTHh2aLJpj3qfZZqiSFcmBA3HQxUNFBsWBmGUT/4I+4+18B\n3H2Tu4fdPQI8SIDV5ua4e0XseTPwVCyGTQ3V0djz5vaOK2YS8K67b4rF2OH7K05z+6jDv3dm9lXg\nfOByjzVCx5pntsZeLyDadn9se8WU5G/X4fsLwMzSgYuBxxvmtec+S3R8oB2/Y6mSFOYDw8xscOwX\n5zRgdkcEEmur/C2wwt3viZsf3w54EbC06boBx5VrZnkNr4l2Ui4lup++Giv2VeCZ9owrzgG/3Dp6\nfzXR3D6aDVwRO0PkVGBnQxNAezCzicB3gcnuvjdufoGZhWKvhwDDgDXtGFdzf7vZwDQzyzSzwbG4\n3mmvuOKcA7zv7uUNM9prnzV3fKA9v2NB96Z3lgfRXvoPiGb473VgHKcTrd4tBhbGHucBfwSWxObP\nBgrbOa4hRM/8WAQsa9hHQG/gJWBV7LlXB+yzHGAr0D1uXofsL6KJaQNQR/RX2tXN7SOiVfv7Y9+5\nJUBpO8e1mmh7c8P37DexspfE/saLgHeBC9o5rmb/dsD3YvtrJTCpvf+Wsfm/B77RpGy77LMkx4d2\n+45pmAsREWmUKs1HIiLSCkoKIiLSSElBREQaKSmIiEgjJQUREWmkpCDShJmF7cCRWQ/bqLqx0TY7\n8poKkaTSOzoAkU6o2t3HdnQQIh1BNQWRVoqNr/9jM3sn9jgmNn+Qmb0UG+DtJTMbGJvf16L3MVgU\ne3wmtqmQmT0YGy//eTPL7rAPJdKEkoLIwbKbNB99OW7ZLncfD/wS+EVs3i+JDl88muigc/fF5t8H\nvOLuY4iO278sNn8YcL+7nwDsIHq1rEinoCuaRZowsyp375pg/lrgbHdfExu0bKO79zazLUSHaqiL\nzd/g7vlmVgkUu/u+uG2UAC+4+7DY9HeBDHf/QfCfTKRlqimIHBpv5nVzZRLZF/c6jPr2pBNRUhA5\nNF+Oe34z9voNoiPvAlwOvBZ7/RJwLYCZhdr5ngUibaJfKCIHy7bYDdtj/uHuDaelZprZ20R/UF0W\nm3cj8JCZfQeoBK6Kzb8JmGlmVxOtEVxLdFROkU5LfQoirRTrUyh19y0dHYtIUNR8JCIijVRTEBGR\nRqopiIhIIyUFERFppKQgIiKNlBRERKSRkoKIiDT6/1ZOkqntKZBRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc65bcd828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc613dfeb8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy',   \n",
    "              optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "train_history = model.fit(x=new_X, y=train_label,  \n",
    "                          validation_split=0.8, epochs=200, \n",
    "                          batch_size=500, verbose=2) \n",
    "\n",
    "\n",
    "show_train_history(train_history,'acc','val_acc')\n",
    "show_train_history(train_history,'loss','val_loss')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((779, 29), (779,))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_testX.shape,test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "576/779 [=====================>........] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(new_testX,test_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "accuracy= 0.98074454467\n",
      "\r",
      " 32/779 [>.............................] - ETA: 1s"
     ]
    }
   ],
   "source": [
    "print('\\n')\n",
    "print('accuracy=',scores[1])\n",
    "\n",
    "prediction = model.predict_classes(test_feature_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_ans = pd.DataFrame({'Actual' :test_label})\n",
    "df_ans['Prediction'] = prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    716\n",
       "1     63\n",
       "Name: Prediction, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ans['Prediction'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    702\n",
       "1.0     77\n",
       "Name: Actual, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ans['Actual'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdc612061d0>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total test case number:  779\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATUAAAE2CAYAAAAAiwWqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc612689e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "cols = ['Actual_1','Actual_0']  \n",
    "rows = ['Prediction_1','Prediction_0']\n",
    "\n",
    "TP = len(df_ans[(df_ans['Prediction'] == df_ans['Actual']) & (df_ans['Actual'] == 1)])\n",
    "TN = len(df_ans[(df_ans['Prediction'] != df_ans['Actual']) & (df_ans['Actual'] == 1)])\n",
    "FP = len(df_ans[(df_ans['Prediction'] != df_ans['Actual']) & (df_ans['Actual'] == 0)])\n",
    "FN = len(df_ans[(df_ans['Prediction'] == df_ans['Actual']) & (df_ans['Actual'] == 0)])\n",
    "\n",
    "conf = np.array([[TP,FP],[TN,FN]])\n",
    "df_cm = pd.DataFrame(conf, columns = [i for i in cols], index = [i for i in rows])\n",
    "\n",
    "f, ax= plt.subplots(figsize = (5, 5))\n",
    "sns.heatmap(df_cm, annot=True, ax=ax, fmt='d') \n",
    "ax.xaxis.set_ticks_position('top') #Making x label be on top is common in textbooks.\n",
    "\n",
    "print('total test case number: ', np.sum(conf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:  779\n",
      "TP:  63\n",
      "FP:  0\n",
      "TN:  14\n",
      "FN:  702\n",
      "sensitivity/Recall:  0.818181818182\n",
      "specificity:  0.980446927374\n",
      "false_positive_rate:  0.0\n",
      "false_negative_rate:  0.181818181818\n",
      "Precision:  1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(779, 0.81818181818181823, 0.98044692737430172, 0.0, 0.18181818181818182, 1.0)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_efficacy(conf):\n",
    "    total_num = np.sum(conf)\n",
    "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n",
    "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n",
    "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n",
    "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n",
    "    TPP=(conf[0][1]+conf[1][1])\n",
    "    PTP=conf[1][1]/(conf[0][1]+conf[1][1])\n",
    "    \n",
    "    print('total_num: ',total_num)\n",
    "    print('TP: ',conf[0][0]) \n",
    "    print('FP: ',conf[0][1])\n",
    "    print('TN: ',conf[1][0])\n",
    "    print('FN: ',conf[1][1])\n",
    "    \n",
    "    print('sensitivity/Recall: ',sen)\n",
    "    print('specificity: ',spe)\n",
    "    print('false_positive_rate: ',false_positive_rate)\n",
    "    print('false_negative_rate: ',false_negative_rate)\n",
    "    print('Precision: ',PTP)\n",
    "    \n",
    "    return total_num, sen, spe, false_positive_rate, false_negative_rate, PTP\n",
    "\n",
    "model_efficacy(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227456/227845 [============================>.] - ETA: 0s\n",
      "\n",
      "accuracy= 0.998604314337\n",
      "227424/227845 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "df_sample2 = df_full.iloc[:,:] \n",
    "\n",
    "feature2 = np.array(df_sample2.values[:,0:29])\n",
    "label2 = np.array(df_sample2.values[:,-1])\n",
    "\n",
    "feature2_trans = scaler.transform(feature2) #using the same scaler as above\n",
    "\n",
    "\n",
    "scores = model.evaluate(feature2_trans, label2)\n",
    "print('\\n')\n",
    "print('accuracy=',scores[1])\n",
    "\n",
    "\n",
    "prediction2 = model.predict_classes(feature2_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    227452\n",
      "          1       0.57      0.79      0.66       393\n",
      "\n",
      "avg / total       1.00      1.00      1.00    227845\n",
      "\n",
      "[[227218    234]\n",
      " [    84    309]]\n"
     ]
    }
   ],
   "source": [
    "prediction2_list = prediction2.reshape(-1).astype(int)\n",
    "label2_list = label2.astype(int)\n",
    "\n",
    "print(classification_report(label2_list, prediction2_list))\n",
    "print(confusion_matrix(label2_list, prediction2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdc611c5588>"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUYAAAEyCAYAAACGZHknAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc611e0c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(label2_list, prediction2_list)\n",
    "f, ax= plt.subplots(figsize = (5, 5))\n",
    "sns.heatmap(conf, annot=True, ax=ax, fmt='d') \n",
    "ax.xaxis.set_ticks_position('top') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:  227845\n",
      "TP:  227218\n",
      "FP:  234\n",
      "TN:  84\n",
      "FN:  309\n",
      "sensitivity/Recall:  0.999630447598\n",
      "specificity:  0.786259541985\n",
      "false_positive_rate:  0.430939226519\n",
      "false_negative_rate:  0.000369552401651\n",
      "Precision:  0.569060773481\n",
      "F1 Score:  0.72525487242\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(227845,\n",
       " 0.99963044759834929,\n",
       " 0.7862595419847328,\n",
       " 0.43093922651933703,\n",
       " 0.00036955240165066741,\n",
       " 0.56906077348066297,\n",
       " 0.72525487242015485)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_efficacy(conf):\n",
    "    total_num = np.sum(conf)\n",
    "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n",
    "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n",
    "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n",
    "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n",
    "    TPP=(conf[0][1]+conf[1][1])\n",
    "    PTP=conf[1][1]/(conf[0][1]+conf[1][1])\n",
    "    F1=2*PTP*sen/(sen+PTP)\n",
    "    \n",
    "    print('total_num: ',total_num)\n",
    "    print('TP: ',conf[0][0]) \n",
    "    print('FP: ',conf[0][1])\n",
    "    print('TN: ',conf[1][0])\n",
    "    print('FN: ',conf[1][1])\n",
    "    \n",
    "    print('sensitivity/Recall: ',sen)\n",
    "    print('specificity: ',spe)\n",
    "    print('false_positive_rate: ',false_positive_rate)\n",
    "    print('false_negative_rate: ',false_negative_rate)\n",
    "    print('Precision: ',PTP)\n",
    "    print('F1 Score: ',F1)\n",
    "    return total_num, sen, spe, false_positive_rate, false_negative_rate, PTP, F1\n",
    "\n",
    "model_efficacy(conf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing MLP perfrmance with Other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing Score:0.989406\n",
      "Testing Score:0.984596\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets,cross_validation,ensemble\n",
    "\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(train_feature_trans,train_label, \n",
    "                                              test_size=0.25, random_state=0,stratify=train_label)\n",
    "clf=ensemble.AdaBoostClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"Traing Score:%f\"%clf.score(train_feature_trans,train_label))\n",
    "print(\"Testing Score:%f\"%clf.score(test_feature_trans,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score:0.995980\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Score:%f\"%clf.score(feature2_trans, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    227452\n",
      "          1       0.29      0.91      0.44       393\n",
      "\n",
      "avg / total       1.00      1.00      1.00    227845\n",
      "\n",
      "[[226572    880]\n",
      " [    36    357]]\n"
     ]
    }
   ],
   "source": [
    "prediction2 = clf.predict(feature2_trans)\n",
    "prediction2_list = prediction2.reshape(-1).astype(int)\n",
    "label2_list = label2.astype(int)\n",
    "\n",
    "print(classification_report(label2_list, prediction2_list))\n",
    "print(confusion_matrix(label2_list, prediction2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:  227845\n",
      "TP:  226572\n",
      "FP:  880\n",
      "TN:  36\n",
      "FN:  357\n",
      "sensitivity/Recall:  0.999841135353\n",
      "specificity:  0.908396946565\n",
      "false_positive_rate:  0.711398544867\n",
      "false_negative_rate:  0.00015886464732\n",
      "Precision:  0.288601455133\n",
      "F1 Score:  0.447913797162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(227845,\n",
       " 0.99984113535267949,\n",
       " 0.90839694656488545,\n",
       " 0.7113985448666128,\n",
       " 0.00015886464732048296,\n",
       " 0.28860145513338725,\n",
       " 0.44791379716211227)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_efficacy(conf):\n",
    "    total_num = np.sum(conf)\n",
    "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n",
    "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n",
    "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n",
    "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n",
    "    TPP=(conf[0][1]+conf[1][1])\n",
    "    PTP=conf[1][1]/(conf[0][1]+conf[1][1])\n",
    "    F1=2*PTP*sen/(sen+PTP)\n",
    "    \n",
    "    print('total_num: ',total_num)\n",
    "    print('TP: ',conf[0][0]) \n",
    "    print('FP: ',conf[0][1])\n",
    "    print('TN: ',conf[1][0])\n",
    "    print('FN: ',conf[1][1])\n",
    "    \n",
    "    print('sensitivity/Recall: ',sen)\n",
    "    print('specificity: ',spe)\n",
    "    print('false_positive_rate: ',false_positive_rate)\n",
    "    print('false_negative_rate: ',false_negative_rate)\n",
    "    print('Precision: ',PTP)\n",
    "    print('F1 Score: ',F1)\n",
    "    return total_num, sen, spe, false_positive_rate, false_negative_rate, PTP, F1\n",
    "\n",
    "conf = confusion_matrix(label2_list, prediction2_list)\n",
    "model_efficacy(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "              presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing Score:0.993900\n",
      "Testing Score:0.982028\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets,cross_validation,ensemble\n",
    "\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(train_feature_trans,train_label, \n",
    "                                              test_size=0.25, random_state=0,stratify=train_label)\n",
    "clf=ensemble.GradientBoostingClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"Traing Score:%f\"%clf.score(train_feature_trans,train_label))\n",
    "print(\"Testing Score:%f\"%clf.score(test_feature_trans,test_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score:0.993500\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Score:%f\"%clf.score(feature2_trans, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.99      1.00    227452\n",
      "          1       0.20      0.94      0.33       393\n",
      "\n",
      "avg / total       1.00      0.99      1.00    227845\n",
      "\n",
      "[[225993   1459]\n",
      " [    22    371]]\n"
     ]
    }
   ],
   "source": [
    "prediction2 = clf.predict(feature2_trans)\n",
    "prediction2_list = prediction2.reshape(-1).astype(int)\n",
    "label2_list = label2.astype(int)\n",
    "\n",
    "print(classification_report(label2_list, prediction2_list))\n",
    "print(confusion_matrix(label2_list, prediction2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:  227845\n",
      "TP:  225993\n",
      "FP:  1459\n",
      "TN:  22\n",
      "FN:  371\n",
      "sensitivity/Recall:  0.999902661328\n",
      "specificity:  0.944020356234\n",
      "false_positive_rate:  0.797267759563\n",
      "false_negative_rate:  9.7338672212e-05\n",
      "Precision:  0.202732240437\n",
      "F1 Score:  0.337113959444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(227845,\n",
       " 0.99990266132778793,\n",
       " 0.94402035623409675,\n",
       " 0.79726775956284157,\n",
       " 9.7338672212021326e-05,\n",
       " 0.20273224043715846,\n",
       " 0.33711395944449257)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_efficacy(conf):\n",
    "    total_num = np.sum(conf)\n",
    "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n",
    "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n",
    "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n",
    "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n",
    "    TPP=(conf[0][1]+conf[1][1])\n",
    "    PTP=conf[1][1]/(conf[0][1]+conf[1][1])\n",
    "    F1=2*PTP*sen/(sen+PTP)\n",
    "    \n",
    "    print('total_num: ',total_num)\n",
    "    print('TP: ',conf[0][0]) \n",
    "    print('FP: ',conf[0][1])\n",
    "    print('TN: ',conf[1][0])\n",
    "    print('FN: ',conf[1][1])\n",
    "    \n",
    "    print('sensitivity/Recall: ',sen)\n",
    "    print('specificity: ',spe)\n",
    "    print('false_positive_rate: ',false_positive_rate)\n",
    "    print('false_negative_rate: ',false_negative_rate)\n",
    "    print('Precision: ',PTP)\n",
    "    print('F1 Score: ',F1)\n",
    "    return total_num, sen, spe, false_positive_rate, false_negative_rate, PTP, F1\n",
    "\n",
    "conf = confusion_matrix(label2_list, prediction2_list)\n",
    "model_efficacy(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traing Score:0.993258\n",
      "Testing Score:0.985879\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets,cross_validation,ensemble\n",
    "\n",
    "X_train,X_test,y_train,y_test = cross_validation.train_test_split(train_feature_trans,train_label, \n",
    "                                              test_size=0.25, random_state=0,stratify=train_label)\n",
    "clf=ensemble.RandomForestClassifier()\n",
    "clf.fit(X_train,y_train)\n",
    "print(\"Traing Score:%f\"%clf.score(train_feature_trans,train_label))\n",
    "print(\"Testing Score:%f\"%clf.score(test_feature_trans,test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Score:0.997801\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing Score:%f\"%clf.score(feature2_trans, label2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    227452\n",
      "          1       0.44      0.92      0.59       393\n",
      "\n",
      "avg / total       1.00      1.00      1.00    227845\n",
      "\n",
      "[[226981    471]\n",
      " [    30    363]]\n"
     ]
    }
   ],
   "source": [
    "prediction2 = clf.predict(feature2_trans)\n",
    "prediction2_list = prediction2.reshape(-1).astype(int)\n",
    "label2_list = label2.astype(int)\n",
    "\n",
    "print(classification_report(label2_list, prediction2_list))\n",
    "print(confusion_matrix(label2_list, prediction2_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:  227845\n",
      "TP:  226981\n",
      "FP:  471\n",
      "TN:  30\n",
      "FN:  363\n",
      "sensitivity/Recall:  0.999867847814\n",
      "specificity:  0.923664122137\n",
      "false_positive_rate:  0.564748201439\n",
      "false_negative_rate:  0.000132152186458\n",
      "Precision:  0.435251798561\n",
      "F1 Score:  0.606491981604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(227845,\n",
       " 0.9998678478135421,\n",
       " 0.92366412213740456,\n",
       " 0.56474820143884896,\n",
       " 0.00013215218645792494,\n",
       " 0.43525179856115109,\n",
       " 0.60649198160400253)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_efficacy(conf):\n",
    "    total_num = np.sum(conf)\n",
    "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n",
    "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n",
    "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n",
    "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n",
    "    TPP=(conf[0][1]+conf[1][1])\n",
    "    PTP=conf[1][1]/(conf[0][1]+conf[1][1])\n",
    "    F1=2*PTP*sen/(sen+PTP)\n",
    "    \n",
    "    print('total_num: ',total_num)\n",
    "    print('TP: ',conf[0][0]) \n",
    "    print('FP: ',conf[0][1])\n",
    "    print('TN: ',conf[1][0])\n",
    "    print('FN: ',conf[1][1])\n",
    "    \n",
    "    print('sensitivity/Recall: ',sen)\n",
    "    print('specificity: ',spe)\n",
    "    print('false_positive_rate: ',false_positive_rate)\n",
    "    print('false_negative_rate: ',false_negative_rate)\n",
    "    print('Precision: ',PTP)\n",
    "    print('F1 Score: ',F1)\n",
    "    return total_num, sen, spe, false_positive_rate, false_negative_rate, PTP, F1\n",
    "conf = confusion_matrix(label2_list, prediction2_list)\n",
    "model_efficacy(conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing On Test Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56512/56962 [============================>.] - ETA: 0s\n",
      "\n",
      "accuracy= 0.998630666058\n",
      "56864/56962 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "df_sample3 = data_test.iloc[:,:] \n",
    "df_sample3.drop('Time', axis=1,  inplace = True)\n",
    "\n",
    "feature3 = np.array(df_sample3.values[:,0:29])\n",
    "label3 = np.array(df_sample3.values[:,-1])\n",
    "\n",
    "feature3_trans = scaler.transform(feature3) \n",
    "\n",
    "\n",
    "scores = model.evaluate(feature3_trans, label3)\n",
    "print('\\n')\n",
    "print('accuracy=',scores[1])\n",
    "\n",
    "\n",
    "prediction3 = model.predict_classes(feature3_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4.16896278e+03,   6.66401817e-01,   9.18999581e-01, ...,\n",
       "          5.40764421e-01,   8.65419195e-01,   2.76125037e-05],\n",
       "       [  4.22008698e+03,   6.36368975e-01,   9.40758797e-01, ...,\n",
       "          6.17251116e-01,   8.45451235e-01,   1.55802680e-05],\n",
       "       [  4.22154506e+03,   6.19898508e-01,   9.35016637e-01, ...,\n",
       "          5.61431689e-01,   8.91674124e-01,   3.21977417e-05],\n",
       "       ..., \n",
       "       [  5.24967912e+03,   6.86469977e-01,   8.76735029e-01, ...,\n",
       "          5.46524970e-01,   7.84926919e-01,  -2.05723589e-06],\n",
       "       [  5.24967912e+03,   6.52840971e-01,   9.00408888e-01, ...,\n",
       "          5.94812706e-01,   7.94817755e-01,   8.09645947e-06],\n",
       "       [  5.24980063e+03,   6.48279698e-01,   8.79909257e-01, ...,\n",
       "          4.90860674e-01,   7.84275837e-01,   1.05715966e-06]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature3_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00     56863\n",
      "          1       0.59      0.69      0.64        99\n",
      "\n",
      "avg / total       1.00      1.00      1.00     56962\n",
      "\n",
      "[[56816    47]\n",
      " [   31    68]]\n"
     ]
    }
   ],
   "source": [
    "prediction3_list = prediction3.reshape(-1).astype(int)\n",
    "label3_list = label3.astype(int)\n",
    "\n",
    "print(classification_report(label3_list, prediction3_list))\n",
    "print(confusion_matrix(label3_list, prediction3_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdc60653320>"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUAAAAEyCAYAAACLeglgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkrJlAJSULQOgpGwZACVl6/8D3OC0ZNBs0C8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdc60645b38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf = confusion_matrix(label3_list, prediction3_list)\n",
    "f, ax= plt.subplots(figsize = (5, 5))\n",
    "sns.heatmap(conf, annot=True, ax=ax, fmt='d') \n",
    "ax.xaxis.set_ticks_position('top') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:  56962\n",
      "TP:  56816\n",
      "FP:  47\n",
      "TN:  31\n",
      "FN:  68\n",
      "sensitivity/Recall:  0.999454676588\n",
      "specificity:  0.686868686869\n",
      "false_positive_rate:  0.408695652174\n",
      "false_negative_rate:  0.000545323411965\n",
      "Precision:  0.591304347826\n",
      "F1 Score:  0.743018756017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(56962,\n",
       " 0.99945467658803455,\n",
       " 0.68686868686868685,\n",
       " 0.40869565217391307,\n",
       " 0.00054532341196545113,\n",
       " 0.59130434782608698,\n",
       " 0.74301875601715317)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def model_efficacy(conf):\n",
    "    total_num = np.sum(conf)\n",
    "    sen = conf[0][0]/(conf[0][0]+conf[1][0])\n",
    "    spe = conf[1][1]/(conf[1][0]+conf[1][1])\n",
    "    false_positive_rate = conf[0][1]/(conf[0][1]+conf[1][1])\n",
    "    false_negative_rate = conf[1][0]/(conf[0][0]+conf[1][0])\n",
    "    TPP=(conf[0][1]+conf[1][1])\n",
    "    PTP=conf[1][1]/(conf[0][1]+conf[1][1])\n",
    "    F1=2*PTP*sen/(sen+PTP)\n",
    "    \n",
    "    print('total_num: ',total_num)\n",
    "    print('TP: ',conf[0][0]) \n",
    "    print('FP: ',conf[0][1])\n",
    "    print('TN: ',conf[1][0])\n",
    "    print('FN: ',conf[1][1])\n",
    "    \n",
    "    print('sensitivity/Recall: ',sen)\n",
    "    print('specificity: ',spe)\n",
    "    print('false_positive_rate: ',false_positive_rate)\n",
    "    print('false_negative_rate: ',false_negative_rate)\n",
    "    print('Precision: ',PTP)\n",
    "    print('F1 Score: ',F1)\n",
    "    return total_num, sen, spe, false_positive_rate, false_negative_rate, PTP, F1\n",
    "\n",
    "model_efficacy(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
